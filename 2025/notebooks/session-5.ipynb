{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2115b015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STD tokens: ['彼', 'は', '昨', '日本', 'を', '買っ', 'て', '読み', '始め', 'まし', 'た', '。']\n",
      "ALT tokens (mode A): ['彼', 'は', '昨', '日本', 'を', '買っ', 'て', '読み', '始め', 'まし', 'た', '。']\n",
      "STD POS: ['PRON', 'ADP', 'NOUN', 'PROPN', 'ADP', 'VERB', 'SCONJ', 'VERB', 'VERB', 'AUX', 'AUX', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from sudachipy import dictionary, tokenizer\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "# 1. Standard pipeline (for reliable POS/DEP):\n",
    "std_nlp = spacy.load(\"ja_core_news_sm\")\n",
    "\n",
    "# 2. Alternate segmentation pipeline (no tagging):\n",
    "sudachi = dictionary.Dictionary().create()\n",
    "MODE = tokenizer.Tokenizer.SplitMode.A  # A=short, C=long\n",
    "\n",
    "alt_nlp = spacy.blank(\"ja\")\n",
    "\n",
    "def sudachi_tokenizer_func(text):\n",
    "    ms = sudachi.tokenize(text, MODE)\n",
    "    words = [m.surface() for m in ms]\n",
    "    spaces = [False]*len(words)\n",
    "    return Doc(alt_nlp.vocab, words=words, spaces=spaces)\n",
    "\n",
    "alt_nlp.tokenizer = sudachi_tokenizer_func\n",
    "\n",
    "text = \"彼は昨日本を買って読み始めました。\"\n",
    "doc_std = std_nlp(text)\n",
    "doc_alt = alt_nlp(text)\n",
    "\n",
    "print(\"STD tokens:\", [t.text for t in doc_std])\n",
    "print(\"ALT tokens (mode A):\", [t.text for t in doc_alt])\n",
    "print(\"STD POS:\", [t.pos_ for t in doc_std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a93cf5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['夏', 'が', '過ぎる', 'と', '御', '香典', 'の', '時間', '。']\n",
      "[('夏', 'NOUN', '名詞-普通名詞-副詞可能'), ('が', 'ADP', '助詞-格助詞'), ('過ぎる', 'VERB', '動詞-非自立可能'), ('と', 'SCONJ', '助詞-接続助詞'), ('御', 'NOUN', '接頭辞'), ('香典', 'NOUN', '名詞-普通名詞-一般'), ('の', 'ADP', '助詞-格助詞'), ('時間', 'NOUN', '名詞-普通名詞-助数詞可能'), ('。', 'PUNCT', '補助記号-句点')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from sudachipy import tokenizer, dictionary\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "sudachi = dictionary.Dictionary().create()\n",
    "MODE = tokenizer.Tokenizer.SplitMode.C  # change to A for short proxy\n",
    "\n",
    "nlp = spacy.blank(\"ja\")\n",
    "\n",
    "def sudachi_tokenizer_func(text):\n",
    "    sudachi_tokens = sudachi.tokenize(text, MODE)\n",
    "    words = [m.surface() for m in sudachi_tokens]\n",
    "    spaces = [False]*len(words)\n",
    "    return Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "\n",
    "# nlp.tokenizer = sudachi_tokenizer_func\n",
    "\n",
    "doc = nlp(\"夏が過ぎると御香典の時間。\")\n",
    "print([t.text for t in doc])\n",
    "print([(t.norm_, t.pos_, t.tag_) for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4487d1de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linguistic-data-analysis-I",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
