{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca3c80c6",
   "metadata": {},
   "source": [
    "# First text analysis with Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd874c1",
   "metadata": {},
   "source": [
    "In this notebook, I will show you how to run a simple text analysis with spaCy package in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9125c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc5197d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"Hi. This is my first awesome sentence to analyze.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede3993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af352ea5",
   "metadata": {},
   "source": [
    "## Print token\n",
    "\n",
    "In the following, you can iterate through the parsed doc and print each token in the `doc` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c92469dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n",
      ".\n",
      "This\n",
      "is\n",
      "my\n",
      "first\n",
      "awesome\n",
      "sentence\n",
      "to\n",
      "analyze\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a4ebf",
   "metadata": {},
   "source": [
    "## Print lemmatized form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5855eb",
   "metadata": {},
   "source": [
    "You can print lemmatized form by `token.lemma_` (do not forget `_` at the end.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da99ecdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\thi\n",
      ".\t.\n",
      "This\tthis\n",
      "is\tbe\n",
      "my\tmy\n",
      "first\tfirst\n",
      "awesome\tawesome\n",
      "sentence\tsentence\n",
      "to\tto\n",
      "analyze\tanalyze\n",
      ".\t.\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4a8237",
   "metadata": {},
   "source": [
    "## Print Part of Speech information\n",
    "\n",
    "You can add more information, such as `pos_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "996190cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\tINTJ\tUH\n",
      ".\tPUNCT\t.\n",
      "This\tPRON\tDT\n",
      "is\tAUX\tVBZ\n",
      "my\tPRON\tPRP$\n",
      "first\tADJ\tJJ\n",
      "awesome\tADJ\tJJ\n",
      "sentence\tNOUN\tNN\n",
      "to\tPART\tTO\n",
      "analyze\tVERB\tVB\n",
      ".\tPUNCT\t.\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.tag_, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8fa2ae",
   "metadata": {},
   "source": [
    "## spaCy token information\n",
    "\n",
    "Some useful token information are following:\n",
    "\n",
    "\n",
    "| code | what it does | example |\n",
    "|----|----|----|\n",
    "| token.lemma_ | lemmatized form | be, child |\n",
    "| token.pos_ | simple POS (Universal Dependency) | NOUN, VERB |\n",
    "| token.tag_ | fine-grained POS (PennTag set) | NN, JJ, VB, BBZ |\n",
    "| token.dep_ | dependency type | amod, advmd |\n",
    "| token.head | token information of the head of the dependency | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a91814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linguistic-data-analysis-I",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
