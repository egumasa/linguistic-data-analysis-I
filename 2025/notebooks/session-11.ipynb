{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca3c80c6",
   "metadata": {},
   "source": [
    "# First dependency analysis with Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd874c1",
   "metadata": {},
   "source": [
    "In this notebook, I will show you how to run a simple dependency analysis with spaCy package in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eec618",
   "metadata": {},
   "source": [
    "First in Python, you will import necessary package. \n",
    "\n",
    "In the following, I import a package called `spacy`.\n",
    "\n",
    "After importing it, I will then load English analysis model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9125c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing spacy package\n",
    "import spacy\n",
    "\n",
    "#loading en_core_web_sm model for English analysis\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8061e3",
   "metadata": {},
   "source": [
    "Great! You have now English analysis model loaded on the system runtime.\n",
    "\n",
    "Next, let's conduct first parsing.\n",
    "\n",
    "We will first define example sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5197d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the example sentence to `example_text`.\n",
    "example_text = \"Hi. This is my first awesome sentence to analyze.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61637484",
   "metadata": {},
   "source": [
    "Okay. Now you have the example sentence. You can verify this by running the following `print(example_text)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea5c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68076f56",
   "metadata": {},
   "source": [
    "Awesome! we have confirmed the example_text.\n",
    "\n",
    "Now, we will pass this example sentence to the spacy model and parse the sentence.\n",
    "\n",
    "The result is then stored in an object `doc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede3993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line parses the example sentence.\n",
    "doc = nlp(example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f7917f",
   "metadata": {},
   "source": [
    "Alright then. We have parsed the first example sentence!\n",
    "Let us verify the parse result next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af352ea5",
   "metadata": {},
   "source": [
    "## Printing the result of analysis.\n",
    "\n",
    "Now that we have parsed sentence called `doc` let's verify the content.\n",
    "\n",
    "`doc` contains multiple `token`s. this token object has parsed information.\n",
    "\n",
    "We can iterate through the doc to return token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92469dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc: #iterate through doc\n",
    "    print(token) # print token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6ec0ac",
   "metadata": {},
   "source": [
    "Okay...? we just print it vertical? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a4ebf",
   "metadata": {},
   "source": [
    "## Print lemmatized form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5855eb",
   "metadata": {},
   "source": [
    "Let's do more.\n",
    "\n",
    "You can print lemmatized form by `token.lemma_` (do not forget `_` at the end.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da99ecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print lemmatized form next to text.\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4a8237",
   "metadata": {},
   "source": [
    "## Print Part of Speech information\n",
    "\n",
    "You can add more information, such as `pos_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996190cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b835f3",
   "metadata": {},
   "source": [
    "## Your turn: Print lemma, pos and tag next to token.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62284204",
   "metadata": {},
   "source": [
    "## spaCy token information\n",
    "\n",
    "Some useful token information are following:\n",
    "\n",
    "\n",
    "| code | what it does | example |\n",
    "|----|----|----|\n",
    "| token.lemma_ | lemmatized form | be, child |\n",
    "| token.pos_ | simple POS (Universal Dependency) | NOUN, VERB |\n",
    "| token.tag_ | fine-grained POS (PennTag set) | NN, JJ, VB, BBZ |\n",
    "| token.dep_ | dependency type | amod, advmd |\n",
    "| token.head | token information of the head of the dependency | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655ead17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    pass # replace this with correct print statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b388b79",
   "metadata": {},
   "source": [
    "# Define a function to print token information to reuse it later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f139e21",
   "metadata": {},
   "source": [
    "Now we have learned how to iterate through the parsed doc and print token information. \n",
    "\n",
    "We now also feel like it's not efficient to write the same code.\n",
    "\n",
    "Now it's time to define a function to do the same and reuse it.\n",
    "\n",
    "Essentially, what I want here is the following:\n",
    "\n",
    "- I want to pass example sentence as input\n",
    "- the code should pass that to spacy and parse\n",
    "- the code should then print information for each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a91814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_print(text: str):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    for token in doc:\n",
    "        print(token.text, token.lemma_, token.pos_, token.dep_, token.head.i, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2858c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_and_print(\"This is an example sentence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353fcb67",
   "metadata": {},
   "source": [
    "You can now try more examples by using `parse_and_print()`\n",
    "\n",
    "Try a few sentence below:\n",
    "- I love beef tongue.\n",
    "- The cat sleeps on the mat.\n",
    "- She quickly reads interesting books.\n",
    "\n",
    "You can add `code blocks` and write `parse_and_print()` with actual sentences inside."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0697fd46",
   "metadata": {},
   "source": [
    "Congratulations!!! You are now able to parse the sentence with spacy and print the information!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linguistic-data-analysis-I",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
