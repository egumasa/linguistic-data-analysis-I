---
title: "Session 6: Hands-on activity #3"
format: revealjs
metadata-files:
  - _slides.yml
  - ../../_metadata.yml
---

# Housekeeping


# Session overview



## Objectives

By the end of this session, you will be able to:

- Compute simple lexical diversity measures using spreadsheet software and dedicated tool
- Explain how modern lexical diversity measures are calculated 
- Compute simple lexical sophistication measures


---

# Review

## Terminology

In this presentation, I will use the following terms:

- **Input text**: The text you want to analyze (e.g., learner produce text).


## Lexical Diversity

- Lexical Diversity is computed internally to text.
- e.g., Type-Token Ratio:
  1. Count the number of unique word (Type) in the input text
  2. Count the number of total word (Token) in the input text
  3. Devide Type by token.

## Lexical Sophistication

- Lexical Sophistication requires external resources to compute.
- To derive a frequency index: 
  1. Compile a frequency list
  2. For each word in the input text, retrieve `frequency score` from the list
     - e.g., tree --> 1,0000
  3. Average the frequency scores (out of item awarded the score)

# Hands-on Activity

---

## Computing simple Lexical Diversity measures by hand 

## Simple Text Example

Cound the type and token of the following texts.

|ID|Text|
|-|----|
| **Text 1**| "The dog ran. The dog jumped. The dog played. The dog barked. The dog ran again and jumped again." |
|**Text 2** | "A curious fox trotted briskly through the meadow, leaping over mossy logs, sniffing wildflowers, and vanishing into golden twilight." |

_Note_ : Texts were generated by GPT for illustration purposes.

## Simple Text Example

|ID|Text| Token | Type |
|-|----|-|-|
| **Text 1**| "The dog ran. The dog jumped. The dog played. The dog barked. The dog ran again and jumped again." | 19 | 8 |
|**Text 2** | "A curious fox trotted briskly through the meadow, leaping over mossy logs, sniffing wildflowers, and vanishing into golden twilight." | 19 | 19 |

_Note_ : Texts were generated by GPT for illustration purposes.

## Impact of Text lengths 

::: {style= "font-size: 65%"}

|ID|Text| Token | Type |
|-|----|-|-|
| **Text 1a**| "The dog ran. The dog jumped. The dog played. The dog barked. The dog ran again and jumped again." | 19 | 8 |
|**Text 1b** | "The dog ran. The dog jumped. The dog barked. The dog played. The dog ran quickly. The dog jumped so high. The dog barked very loudly. The dog played, sat, and rolled. The dog sneezed. The dog ate the food." | 40 | 18 |
|**Text 1c**| "The parrot squawked loudly. The parrot chirped again. A toucan perched nearby. The parrot fluttered. Wings flapped softly. The parrot chirped again. Feathers shimmered under sunlight. The crow cawed. The parrot glided low. The air shimmered. The owl blinked slowly. The parrot perched again. The owl blinked slowly. The parrot shrieked. The parrot chirped nearby again. The parrot squawked again." | 60 | 27 |

_Note_ : Texts were generated by GPT for illustration purposes.

:::

## Let's calculate some classical Lexical Diversity indices

- Open Google Spreadsheet

- Calculate the lexical diversity indices on the next page.

## Some classic lexical diversity 

We calculate this for illustration but **NEVER use these in your study**.

- $TTR = {nType \over nToken}$
- $RootTTR = {nType \over \sqrt{nToken}}$
- $LogTTR = {\log(nType) \over \log(nToken)}$
- $Maas = {\log(nTokens) - \log(nTypes) \over \log(nToken)^2}$

## What should we actually use then?

- The Measure of Textual Lexical Diversity (MTLD)
- Moving-Average Type Token Ratio (MATTR)

â†’ These are shown as more robust indices of LD. 


## Using TAALED desktop version

- We can use [Tool for the Automatic Analysis of Lexical Diversity (TAALED)](https://www.linguisticanalysistools.org/taaled.html)
- Download it to your computer and we will use it to compute modern LD measures

![TAALED](../../assets/session-6/taaled_orig.png)

## Setting up

- Click the software icon after download


- For mac users, the system will issue warning, you must follow the following step:
  - Go to `setting` and select `Privacy & Security`
  - If you have already attempted to open the software, there will be `Open Anyway` button.
  - Click `Open Anyway` and that will allow Mac to open the software.


## Selecting indics

You can then wait for the TAALED app to start up.

![TAALED](../../assets/session-6/TAALED-landing.png)

## Options

### Word analysis options
- All words: Conduct analysis including all words.
- Content words: Conduct analysis with content words only.
- Function words: Conduct analysis with function words only.

## Options
### Index selection

Select the indices you need in the results. 
Three variants of MTLD are available.

- **MTLD Original**:
- **MTLD MA Bi**: Moving Average Bidirectional
- **MTLD MA Wrap**: If there is words left in the final `factor`, come back to the first part and complete the analysis.

## Options

### Input and output options

- You can choose the input folder by selection

### Output option

- Ticking the  `Individual Item Output` button allows you to have POS analysis

```markdown
parent_cw_nn
and_fw
teacher_cw_nn
disagree_cw_vb
that_fw
```

## Run the analysis

- Press `Process Texts` and wait the following display.

![Analysis complete](../../assets/session-6/TAALED-endmessage.png)

## Let's take a look at the `csv` file

- What's CSV?
  - CSV (Comma Separated Values) file is a file extension like others (txt, docx).
  - It allows table like representation of data (like excel) separated by comma.

The Raw data (if you open it with text editor) should look like the following:

```markdown
filename,basic_ntokens,basic_ntypes,basic_ncontent_tokens,basic_ncontent_types,basic_nfunction_tokens,basic_nfunction_types,lexical_density_types,lexical_density_tokens,maas_ttr_aw,mattr50_aw,hdd42_aw,mtld_original_aw,mtld_ma_bi_aw,mtld_ma_wrap_aw
W_CHN_PTJ0_004_B1_2_ORIG.txt,267,124,135,75,132,49,0.6048387096774194,0.5056179775280899,0.056571333957257205,0.7793577981651377,0.7981161136859327,68.68659119235562,65.84622666144406,61.50561797752809
W_JPN_SMK0_015_B1_2_ORIG.txt,302,138,129,82,173,56,0.5942028985507246,0.4271523178807947,0.05530143602594381,0.777865612648221,0.7974803670481457,68.38677597714803,67.6645170484911,65.22185430463576
```

## Opening csv file in a spreadsheet software

- You can open csv file in Excel (or any other spreadsheet software)


## Questions?



## Lemmatize? 

- What do you think is the effect of lemmatization on the lexical diversity measures?
- Should we lemmatize? Why or why not?

---

## Computing simple Lexical Sophisitcation measures 


## Lexical sophistication

There are a number of lexical sophistication measures for English (+ 300).

- 12 categories of measures (Eguchi & Kyle, 2020)
  - Frequency
  - Range
  - Psycholinguistic Norm


## Typical operationalization

- **Operationalization** means 

- Typically, lexical sophistication (LS) is calculated as an average:

  Typical LS score = $$Total \; LS \; score \over nToken \; with \; LS \; score$$

- Average is just a convenient choice. 


## Using an emulation of TAALES

- Since the desktop version of TAALES is unstable these days, we will use a simple web application.


--- 


# Submission

- Japanese Word Frequency List and small write-up (5 points)
- The Google Spreadsheet with calculation of lexical diversity indices (5 points)
- Write up of Japanese lexical sophistication analysis (5 points)


