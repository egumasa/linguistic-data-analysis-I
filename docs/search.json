[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Linguistic Data Analysis I",
    "section": "",
    "text": "Under Construction\n\n\n\nThis course website is currently under construction and will be ready for the class starting August 2nd, 2025. Content is being actively developed and updated."
  },
  {
    "objectID": "index.html#welcome-to-linguistic-data-analysis-i",
    "href": "index.html#welcome-to-linguistic-data-analysis-i",
    "title": "Linguistic Data Analysis I",
    "section": "Welcome to Linguistic Data Analysis I",
    "text": "Welcome to Linguistic Data Analysis I\nThis intensive 5-day graduate course introduces students to corpus linguistics and learner language analysis. Through hands-on activities and practical applications, you‚Äôll learn to use computational tools to analyze linguistic data, with a special focus on learner corpora.\n\n\n\n\n\n\nQuick Links\n\n\n\n\nüìã Course Syllabus\nüìÖ Schedule\nüíª Sessions\nüìù Assignments\nüîß Resources"
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "Linguistic Data Analysis I",
    "section": "Course Overview",
    "text": "Course Overview\n\n\n\nWhat You‚Äôll Learn\n\nCorpus analysis techniques\nLearner language analysis methods\nPractical applications with real corpora\nResearch methodology in corpus linguistics\n\n\n\n\nKey Tools\n\nAntConc - Corpus analysis software\nBYU Corpora - Online corpus interfaces\nPython - Text processing (via Google Colab)\nJASP - Statistical analysis"
  },
  {
    "objectID": "index.html#course-structure",
    "href": "index.html#course-structure",
    "title": "Linguistic Data Analysis I",
    "section": "Course Structure",
    "text": "Course Structure\nThe course is organized into 5 intensive days:\n\n\n\nDay\nTheme\nSessions\n\n\n\n\nDay 1\nIntroduction & Corpus Basics\n\n\n\nDay 2\nAnalysis of Vocabulary & Multiword Units (1)\n\n\n\nDay 3\nAnalysis of Vocabulary & Multiword Units (2)\n\n\n\nDay 4\nAnalysis of Grammar\n\n\n\nDay 5\nAdvanced Topics & Projects"
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Linguistic Data Analysis I",
    "section": "Getting Started",
    "text": "Getting Started\n\nReview the syllabus for course policies and expectations\nCheck the detailed schedule for session timings\nInstall required software using our setup guides\nBrowse the resources section for helpful materials"
  },
  {
    "objectID": "index.html#instructor-information",
    "href": "index.html#instructor-information",
    "title": "Linguistic Data Analysis I",
    "section": "Instructor Information",
    "text": "Instructor Information\nInstructor: Masaki Eguchi, Ph.D.\nEmail: You can contact me through Google Classroom"
  },
  {
    "objectID": "index.html#course-communication",
    "href": "index.html#course-communication",
    "title": "Linguistic Data Analysis I",
    "section": "Course Communication",
    "text": "Course Communication\n\n\n\n\n\n\nStay Connected\n\n\n\n\nCourse Website: This site\nCommunication: Google Classroom\nAssignment Submission: Google Classroom"
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Linguistic Data Analysis I",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThis course builds on materials and approaches from:\n\nDr.¬†Kris Kyle (University of Oregon) for his previous corpus linguistics/NLP classes from University of Hawai‚Äôi and Oregon.\nDr.¬†Andrew Heiss (Georgia State University) for his Quarto-based materials and website settings, which significantly enhanced the accessibility of the course content."
  },
  {
    "objectID": "resources/corpora/available-corpora.html",
    "href": "resources/corpora/available-corpora.html",
    "title": "Available Corpora",
    "section": "",
    "text": "Content to be added.\n\nCorpusMate\nMontclair State University - CORAL lab",
    "crumbs": [
      "Resources",
      "Corpora",
      "Available Corpora"
    ]
  },
  {
    "objectID": "resources/corpora/available-corpora.html#placeholder",
    "href": "resources/corpora/available-corpora.html#placeholder",
    "title": "Available Corpora",
    "section": "",
    "text": "Content to be added.\n\nCorpusMate\nMontclair State University - CORAL lab",
    "crumbs": [
      "Resources",
      "Corpora",
      "Available Corpora"
    ]
  },
  {
    "objectID": "resources/corpora/index.html",
    "href": "resources/corpora/index.html",
    "title": "Corpora Resources",
    "section": "",
    "text": "Available Corpora\nLearner Corpora",
    "crumbs": [
      "Resources",
      "Corpora",
      "Corpora Resources"
    ]
  },
  {
    "objectID": "resources/corpora/index.html#resources",
    "href": "resources/corpora/index.html#resources",
    "title": "Corpora Resources",
    "section": "",
    "text": "Available Corpora\nLearner Corpora",
    "crumbs": [
      "Resources",
      "Corpora",
      "Corpora Resources"
    ]
  },
  {
    "objectID": "resources/tools/byu-corpora-guide.html",
    "href": "resources/tools/byu-corpora-guide.html",
    "title": "English Corpora Guide",
    "section": "",
    "text": "The EnglishCorpora.org, formally BYU (Brigham Young University) corpora, provide web-based interfaces to some of the largest and most widely-used corpora in the world. These include COCA (Corpus of Contemporary American English), BNC (British National Corpus), and many others.",
    "crumbs": [
      "Resources",
      "Tools",
      "English Corpora Guide"
    ]
  },
  {
    "objectID": "resources/tools/byu-corpora-guide.html#overview",
    "href": "resources/tools/byu-corpora-guide.html#overview",
    "title": "English Corpora Guide",
    "section": "",
    "text": "The EnglishCorpora.org, formally BYU (Brigham Young University) corpora, provide web-based interfaces to some of the largest and most widely-used corpora in the world. These include COCA (Corpus of Contemporary American English), BNC (British National Corpus), and many others.",
    "crumbs": [
      "Resources",
      "Tools",
      "English Corpora Guide"
    ]
  },
  {
    "objectID": "resources/tools/byu-corpora-guide.html#available-corpora",
    "href": "resources/tools/byu-corpora-guide.html#available-corpora",
    "title": "English Corpora Guide",
    "section": "Available Corpora",
    "text": "Available Corpora\n\nMajor English Corpora\n\nCOCA (Corpus of Contemporary American English): 1 billion words, 1990-2019\nBNC (British National Corpus): 100 million words\nGloWbE (Global Web-Based English): 1.9 billion words\nNOW (News on the Web): 14+ billion words, updated daily\nCOHA (Corpus of Historical American English): 400 million words, 1810-2009\n\n\n\nSpecialized Corpora\n\nSOAP (Corpus of American Soap Operas): 100 million words\nTIME (TIME Magazine Corpus): 100 million words, 1920s-2000s\nWikipedia Corpus: 1.9 billion words",
    "crumbs": [
      "Resources",
      "Tools",
      "English Corpora Guide"
    ]
  },
  {
    "objectID": "resources/tools/byu-corpora-guide.html#registration-and-access",
    "href": "resources/tools/byu-corpora-guide.html#registration-and-access",
    "title": "English Corpora Guide",
    "section": "Registration and Access",
    "text": "Registration and Access\n\nFree Access\n\nVisit english-corpora.org\nClick on desired corpus\nRegister for free account\nLimited to 20 queries per day\n\n\n\nAcademic License (or through purchase)\n\nExtended query limits\nDownload capabilities\nAvailable through institution",
    "crumbs": [
      "Resources",
      "Tools",
      "English Corpora Guide"
    ]
  },
  {
    "objectID": "resources/tools/antconc-guide.html",
    "href": "resources/tools/antconc-guide.html",
    "title": "AntConc Guide",
    "section": "",
    "text": "We will use AntConc, a one of the most widely used corpus tool developed by Laurence ANTHONY (Waseda University).\nThanksfully, Laurence has shared tutorials on basic features of AntConc on Youtube.\nBefore Day 1, I would like you to do the followings.\n\nDownload AntConc\n\n\nVisit AntConc Website; download the software to your computer.\n\n\nWatch the following tutorial videos\n\n\nLaurence Anthony‚Äôs intro to AntConc\n\nGetting started (10 mins)\nCorpus manager Basics (18 mins)\nKWIC tool basics (17 mins)\n\n\nIf you are unsure about these steps, do not hesitate to reach out to me through google classroom or through email.",
    "crumbs": [
      "Resources",
      "Tools",
      "AntConc Guide"
    ]
  },
  {
    "objectID": "resources/tools/antconc-guide.html#overview",
    "href": "resources/tools/antconc-guide.html#overview",
    "title": "AntConc Guide",
    "section": "",
    "text": "We will use AntConc, a one of the most widely used corpus tool developed by Laurence ANTHONY (Waseda University).\nThanksfully, Laurence has shared tutorials on basic features of AntConc on Youtube.\nBefore Day 1, I would like you to do the followings.\n\nDownload AntConc\n\n\nVisit AntConc Website; download the software to your computer.\n\n\nWatch the following tutorial videos\n\n\nLaurence Anthony‚Äôs intro to AntConc\n\nGetting started (10 mins)\nCorpus manager Basics (18 mins)\nKWIC tool basics (17 mins)\n\n\nIf you are unsure about these steps, do not hesitate to reach out to me through google classroom or through email.",
    "crumbs": [
      "Resources",
      "Tools",
      "AntConc Guide"
    ]
  },
  {
    "objectID": "resources/code-examples/python/index.html",
    "href": "resources/code-examples/python/index.html",
    "title": "Python Notebooks",
    "section": "",
    "text": "Python notebooks for corpus analysis tasks."
  },
  {
    "objectID": "resources/code-examples/python/index.html#available-notebooks",
    "href": "resources/code-examples/python/index.html#available-notebooks",
    "title": "Python Notebooks",
    "section": "",
    "text": "Python notebooks for corpus analysis tasks."
  },
  {
    "objectID": "resources/code-examples/python/index.html#how-to-use",
    "href": "resources/code-examples/python/index.html#how-to-use",
    "title": "Python Notebooks",
    "section": "How to Use",
    "text": "How to Use\n\nClick on any notebook link\nOpen in Google Colab\nMake a copy to your Google Drive\nRun cells sequentially"
  },
  {
    "objectID": "2025/sessions/day1/session2.html",
    "href": "2025/sessions/day1/session2.html",
    "title": "Session 2:",
    "section": "",
    "text": "Session 2 covers foundational concepts of corpus linguistics.",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 2:"
    ]
  },
  {
    "objectID": "2025/sessions/day1/session2.html#one-liner",
    "href": "2025/sessions/day1/session2.html#one-liner",
    "title": "Session 2:",
    "section": "",
    "text": "Session 2 covers foundational concepts of corpus linguistics.",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 2:"
    ]
  },
  {
    "objectID": "2025/sessions/day1/session2.html#learning-objectives",
    "href": "2025/sessions/day1/session2.html#learning-objectives",
    "title": "Session 2:",
    "section": "üéØ Learning Objectives",
    "text": "üéØ Learning Objectives\n\nBy the end of this session, students will be able to:\n\nDefine corpus linguistics as an empirical methodology\nExplain key limitations of introspection in linguistic research\nDescribe the role of frequency data and patterns in corpus analysis\nIdentify and explain the basic steps in corpus-based research\nReflect on their own stance toward data, intuition, and linguistic evidence",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 2:"
    ]
  },
  {
    "objectID": "2025/sessions/day1/session2.html#key-concepts",
    "href": "2025/sessions/day1/session2.html#key-concepts",
    "title": "Session 2:",
    "section": "üîë Key Concepts",
    "text": "üîë Key Concepts\n\nCorpus linguistics\nBalanced Corpus\nReference Corpus\nLearner Corpus\nCorpus representativeness",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 2:"
    ]
  },
  {
    "objectID": "2025/sessions/day1/session2.html#required-readings",
    "href": "2025/sessions/day1/session2.html#required-readings",
    "title": "Session 2:",
    "section": "üìö Required Readings",
    "text": "üìö Required Readings\n\nStefanowitsch (2020) Ch. 1 Freely available online\nStefanowitsch (2020) Ch. 2 Freely available online\n(Skim) Durrant (2023) Ch. 1",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 2:"
    ]
  },
  {
    "objectID": "2025/sessions/day1/session2.html#materials",
    "href": "2025/sessions/day1/session2.html#materials",
    "title": "Session 2:",
    "section": "Materials",
    "text": "Materials\n\nSlides (Under construction)",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 2:"
    ]
  },
  {
    "objectID": "2025/sessions/day1/session2.html#reflection",
    "href": "2025/sessions/day1/session2.html#reflection",
    "title": "Session 2:",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 2:"
    ]
  },
  {
    "objectID": "2025/sessions/day1/index.html",
    "href": "2025/sessions/day1/index.html",
    "title": "Day 1: Introduction and Foundations",
    "section": "",
    "text": "Day 1 introduces basic concepts of corpus linguistics.",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Day 1: Introduction and Foundations"
    ]
  },
  {
    "objectID": "2025/sessions/day1/index.html#overview",
    "href": "2025/sessions/day1/index.html#overview",
    "title": "Day 1: Introduction and Foundations",
    "section": "",
    "text": "Day 1 introduces basic concepts of corpus linguistics.",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Day 1: Introduction and Foundations"
    ]
  },
  {
    "objectID": "2025/sessions/day1/index.html#key-concepts",
    "href": "2025/sessions/day1/index.html#key-concepts",
    "title": "Day 1: Introduction and Foundations",
    "section": "Key Concepts",
    "text": "Key Concepts\n\nlinguistic intuition\nscientific hypothesis and data\nKWIC\nConcordancing",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Day 1: Introduction and Foundations"
    ]
  },
  {
    "objectID": "2025/sessions/day1/index.html#preparation",
    "href": "2025/sessions/day1/index.html#preparation",
    "title": "Day 1: Introduction and Foundations",
    "section": "Preparation",
    "text": "Preparation\nBefore Day 1:\n\nRead:\n\nStefanowitsch (2020) Ch. 1. Freely available online\nStefanowitsch (2020) Ch. 2. Freely available online\n\nSkim:\n\nDurrant (2023) Ch. 1.",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Day 1: Introduction and Foundations"
    ]
  },
  {
    "objectID": "2025/sessions/day1/index.html#schedule",
    "href": "2025/sessions/day1/index.html#schedule",
    "title": "Day 1: Introduction and Foundations",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nTime\nActivity\n\n\n\n\n10:30-12:00\nSession 1: Introduction\n\n\n12:00-13:00\nLunch\n\n\n13:00-14:30\nSession 2:\n\n\n14:30-14:40\nBreak\n\n\n14:40-16:10\nSession 3: First Hands-on Activity",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Day 1: Introduction and Foundations"
    ]
  },
  {
    "objectID": "2025/sessions/day1/index.html#assignments",
    "href": "2025/sessions/day1/index.html#assignments",
    "title": "Day 1: Introduction and Foundations",
    "section": "Assignments",
    "text": "Assignments\n\nDue Tomorrow: Hands-on Assignment 1\nComplete basic corpus search exercise",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Day 1: Introduction and Foundations"
    ]
  },
  {
    "objectID": "2025/sessions/day1/index.html#reflection",
    "href": "2025/sessions/day1/index.html#reflection",
    "title": "Day 1: Introduction and Foundations",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Day 1: Introduction and Foundations"
    ]
  },
  {
    "objectID": "2025/sessions/outline.html",
    "href": "2025/sessions/outline.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\n\nSession 1\n\n\nSession 2\n\n\nSession 3"
  },
  {
    "objectID": "2025/sessions/day5/index.html",
    "href": "2025/sessions/day5/index.html",
    "title": "Day 5: Advanced Topics and Final Project",
    "section": "",
    "text": "Day 5 explores cutting-edge applications of Large Language Models in corpus linguistics and provides dedicated time for final project development.",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Day 5: Advanced Topics and Final Project"
    ]
  },
  {
    "objectID": "2025/sessions/day5/index.html#overview",
    "href": "2025/sessions/day5/index.html#overview",
    "title": "Day 5: Advanced Topics and Final Project",
    "section": "",
    "text": "Day 5 explores cutting-edge applications of Large Language Models in corpus linguistics and provides dedicated time for final project development.",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Day 5: Advanced Topics and Final Project"
    ]
  },
  {
    "objectID": "2025/sessions/day5/index.html#key-concepts",
    "href": "2025/sessions/day5/index.html#key-concepts",
    "title": "Day 5: Advanced Topics and Final Project",
    "section": "Key Concepts",
    "text": "Key Concepts\n\nLarge Language Models (LLMs) and Language Generation\nPrompt engineering\nFine-tuning\nLLM-assisted linguistic annotation\nResearch design and methodology\nProject presentation skills",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Day 5: Advanced Topics and Final Project"
    ]
  },
  {
    "objectID": "2025/sessions/day5/index.html#preparation",
    "href": "2025/sessions/day5/index.html#preparation",
    "title": "Day 5: Advanced Topics and Final Project",
    "section": "Preparation",
    "text": "Preparation\nBefore Day 5:\n\nRead:\n\nMizumoto, A., Shintani, N., Sasaki, M., & Teng, M. F. (2024). Testing the viability of ChatGPT as a companion in L2 writing accuracy assessment. Research Methods in Applied Linguistics, 3(2), 100116.\n\nSkim:\n\nKim, M., & Lu, X. (2024). Exploring the potential of using ChatGPT for rhetorical move-step analysis. Journal of English for Academic Purposes, 71, 101422.",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Day 5: Advanced Topics and Final Project"
    ]
  },
  {
    "objectID": "2025/sessions/day5/index.html#schedule",
    "href": "2025/sessions/day5/index.html#schedule",
    "title": "Day 5: Advanced Topics and Final Project",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nTime\nActivity\n\n\n\n\n10:30-12:00\nSession 13: LLMs in Linguistic Analysis\n\n\n12:00-13:00\nLunch\n\n\n13:00-14:30\nSession 14: Group Project Time\n\n\n14:30-14:40\nBreak\n\n\n14:40-16:10\nSession 15: Project Presentations and Wrap-up",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Day 5: Advanced Topics and Final Project"
    ]
  },
  {
    "objectID": "2025/sessions/day5/index.html#assignments",
    "href": "2025/sessions/day5/index.html#assignments",
    "title": "Day 5: Advanced Topics and Final Project",
    "section": "Assignments",
    "text": "Assignments\n\nFinal Project: Final Project Guidelines\nGroup presentations today\nFinal submission deadline: [Check syllabus]",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Day 5: Advanced Topics and Final Project"
    ]
  },
  {
    "objectID": "2025/sessions/day5/index.html#reflection",
    "href": "2025/sessions/day5/index.html#reflection",
    "title": "Day 5: Advanced Topics and Final Project",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Day 5: Advanced Topics and Final Project"
    ]
  },
  {
    "objectID": "2025/sessions/day5/session14.html",
    "href": "2025/sessions/day5/session14.html",
    "title": "Session 14",
    "section": "",
    "text": "Group project time. Please use the time wisely.",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Session 14"
    ]
  },
  {
    "objectID": "2025/sessions/day5/session14.html#one-liner",
    "href": "2025/sessions/day5/session14.html#one-liner",
    "title": "Session 14",
    "section": "",
    "text": "Group project time. Please use the time wisely.",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Session 14"
    ]
  },
  {
    "objectID": "2025/sessions/day5/session14.html#reflection",
    "href": "2025/sessions/day5/session14.html#reflection",
    "title": "Session 14",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Session 14"
    ]
  },
  {
    "objectID": "2025/sessions/day2/index.html",
    "href": "2025/sessions/day2/index.html",
    "title": "Day 2: Analyzing Vocabulary",
    "section": "",
    "text": "Day 2 focuses on analyzing vocabulary in corpus linguistics, introducing concepts of lexical richness, diversity, and sophistication.",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Day 2: Analyzing Vocabulary"
    ]
  },
  {
    "objectID": "2025/sessions/day2/index.html#overview",
    "href": "2025/sessions/day2/index.html#overview",
    "title": "Day 2: Analyzing Vocabulary",
    "section": "",
    "text": "Day 2 focuses on analyzing vocabulary in corpus linguistics, introducing concepts of lexical richness, diversity, and sophistication.",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Day 2: Analyzing Vocabulary"
    ]
  },
  {
    "objectID": "2025/sessions/day2/index.html#key-concepts",
    "href": "2025/sessions/day2/index.html#key-concepts",
    "title": "Day 2: Analyzing Vocabulary",
    "section": "Key Concepts",
    "text": "Key Concepts\n\nLexical Richness (text internal vs external measures)\nLexical Diversity (Type-Token Ratio, MTLD)\nLexical Sophistication (frequency, concreteness, phonological neighbors)\nLexical profiling\nFrequency Lists and Zipf law",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Day 2: Analyzing Vocabulary"
    ]
  },
  {
    "objectID": "2025/sessions/day2/index.html#preparation",
    "href": "2025/sessions/day2/index.html#preparation",
    "title": "Day 2: Analyzing Vocabulary",
    "section": "Preparation",
    "text": "Preparation\nBefore Day 2:\n\nRead:\n\nDurrant Ch. 3\n(Skim) Eguchi, M., & Kyle, K. (2020). Continuing to Explore the Multidimensional Nature of Lexical Sophistication. The Modern Language Journal, 104(2), 381‚Äì400.\n\nSkim:\n\nDurrant Ch. 4 (Ignore R codes if you are not familiar)\n\nWatch:\n\nLaurence Anthony‚Äôs intro to AntConc\n\nGetting started (10 mins)\nCorpus manager Basics (18 mins) \nWord list tool basics (7 mins)",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Day 2: Analyzing Vocabulary"
    ]
  },
  {
    "objectID": "2025/sessions/day2/index.html#schedule",
    "href": "2025/sessions/day2/index.html#schedule",
    "title": "Day 2: Analyzing Vocabulary",
    "section": "Schedule",
    "text": "Schedule\n\n\n\n\n\n\n\nTime\nActivity\n\n\n\n\n10:30-12:00\nSession 4: Analyzing vocabulary (1) ‚Äî Conceptual overview\n\n\n12:00-13:00\nLunch\n\n\n13:00-14:30\nSession 5: Frequency Analysis and Lexical Profiling\n\n\n14:30-14:40\nBreak\n\n\n14:40-16:10\nSession 6: Computing Lexical Measures",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Day 2: Analyzing Vocabulary"
    ]
  },
  {
    "objectID": "2025/sessions/day2/index.html#assignments",
    "href": "2025/sessions/day2/index.html#assignments",
    "title": "Day 2: Analyzing Vocabulary",
    "section": "Assignments",
    "text": "Assignments\n\nDue Tomorrow: Hands-on Assignment 2\nComplete lexical analysis exercises using AntConc and web applications",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Day 2: Analyzing Vocabulary"
    ]
  },
  {
    "objectID": "2025/sessions/day2/index.html#reflection",
    "href": "2025/sessions/day2/index.html#reflection",
    "title": "Day 2: Analyzing Vocabulary",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Day 2: Analyzing Vocabulary"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session5.html#learning-objectives",
    "href": "2025/sessions/day2/session5.html#learning-objectives",
    "title": "Session 5",
    "section": "üéØ Learning Objectives",
    "text": "üéØ Learning Objectives\nBy the end of this session, you will be able to:\n\nCompute frequency of a single-word lexical item in reference corpora\nDerive vocabulary frequency list using concordancing software (e.g., AntConc)\nConduct Lexical Profiling using a web-application or desktop application (e.g., AntWordProfiler)",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 5"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session5.html#key-concepts",
    "href": "2025/sessions/day2/session5.html#key-concepts",
    "title": "Session 5",
    "section": "üîë Key Concepts",
    "text": "üîë Key Concepts\n\nLexical profiling\nFrequency Lists\nZipf law\nLexical coverage",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 5"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session5.html#tools-used",
    "href": "2025/sessions/day2/session5.html#tools-used",
    "title": "Session 5",
    "section": "üõ†Ô∏è Tools Used",
    "text": "üõ†Ô∏è Tools Used\n\nAntConc\nAntWordProfiler\nNew Word Levels Checker\nLexTutor",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 5"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session5.html#materials",
    "href": "2025/sessions/day2/session5.html#materials",
    "title": "Session 5",
    "section": "Materials",
    "text": "Materials\n\nSlides (Under construction)",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 5"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session5.html#reflection",
    "href": "2025/sessions/day2/session5.html#reflection",
    "title": "Session 5",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 5"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session5.html#frequency-list",
    "href": "2025/sessions/day2/session5.html#frequency-list",
    "title": "Session 5",
    "section": "Frequency list",
    "text": "Frequency list",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 5"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session5.html#lexical-profiling",
    "href": "2025/sessions/day2/session5.html#lexical-profiling",
    "title": "Session 5",
    "section": "Lexical Profiling",
    "text": "Lexical Profiling",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 5"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session5.html#keyness-analysis",
    "href": "2025/sessions/day2/session5.html#keyness-analysis",
    "title": "Session 5",
    "section": "Keyness Analysis",
    "text": "Keyness Analysis",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 5"
    ]
  },
  {
    "objectID": "2025/sessions/day3/session8.html#learning-objectives",
    "href": "2025/sessions/day3/session8.html#learning-objectives",
    "title": "Session 8",
    "section": "üéØ Learning Objectives",
    "text": "üéØ Learning Objectives\n\nBy the end of this session, students will be able to:\n\nSearch for window-based collocations and n-grams in AntConc\nCalculate commonly used strengths of association measures by hand using spreadsheet software\nDiscuss benefits and drawbacks of different strength of association measures",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Session 8"
    ]
  },
  {
    "objectID": "2025/sessions/day3/session8.html#key-concepts",
    "href": "2025/sessions/day3/session8.html#key-concepts",
    "title": "Session 8",
    "section": "üîë Key Concepts",
    "text": "üîë Key Concepts\n\nn-gram search\nWindow-based collocation search\nStrengths of Association measures ‚Äî T-score, Mutual Information, LogDice",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Session 8"
    ]
  },
  {
    "objectID": "2025/sessions/day3/session8.html#required-readings",
    "href": "2025/sessions/day3/session8.html#required-readings",
    "title": "Session 8",
    "section": "üìö Required Readings",
    "text": "üìö Required Readings\n\n(Skim) Durrant (2023) Ch. 8 (Ignore R codes if you are not familiar)",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Session 8"
    ]
  },
  {
    "objectID": "2025/sessions/day3/session8.html#materials",
    "href": "2025/sessions/day3/session8.html#materials",
    "title": "Session 8",
    "section": "Materials",
    "text": "Materials\n\nSlides (Under construction)",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Session 8"
    ]
  },
  {
    "objectID": "2025/sessions/day3/session8.html#reflection",
    "href": "2025/sessions/day3/session8.html#reflection",
    "title": "Session 8",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Session 8"
    ]
  },
  {
    "objectID": "2025/sessions/day3/index.html",
    "href": "2025/sessions/day3/index.html",
    "title": "Day 3: Multiword Units and Collocations",
    "section": "",
    "text": "Day 3 explores multiword units, collocations, and statistical measures for analyzing word combinations in corpus linguistics.",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Day 3: Multiword Units and Collocations"
    ]
  },
  {
    "objectID": "2025/sessions/day3/index.html#overview",
    "href": "2025/sessions/day3/index.html#overview",
    "title": "Day 3: Multiword Units and Collocations",
    "section": "",
    "text": "Day 3 explores multiword units, collocations, and statistical measures for analyzing word combinations in corpus linguistics.",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Day 3: Multiword Units and Collocations"
    ]
  },
  {
    "objectID": "2025/sessions/day3/index.html#key-concepts",
    "href": "2025/sessions/day3/index.html#key-concepts",
    "title": "Day 3: Multiword Units and Collocations",
    "section": "Key Concepts",
    "text": "Key Concepts\n\nTypes of multiword units (collocation, n-grams, lexical bundles)\nAssociation strengths (t-score, Mutual Information, LogDice)\nContext window vs dependency bigram approaches\nn-gram search and window-based collocation search\nLinear regression analysis for corpus data",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Day 3: Multiword Units and Collocations"
    ]
  },
  {
    "objectID": "2025/sessions/day3/index.html#preparation",
    "href": "2025/sessions/day3/index.html#preparation",
    "title": "Day 3: Multiword Units and Collocations",
    "section": "Preparation",
    "text": "Preparation\nBefore Day 3:\n\nRead:\n\nDurrant (2023) Ch. 7\nGablasova, D., Brezina, V., & McEnery, T. (2017). Collocations in Corpus‚ÄêBased Language Learning Research. Language Learning, 67(S1), 155‚Äì179.\n\nSkim:\n\nDurrant (2023) Ch. 8 (Ignore R codes if you are not familiar)\nEguchi & Kyle (2020) - review if needed",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Day 3: Multiword Units and Collocations"
    ]
  },
  {
    "objectID": "2025/sessions/day3/index.html#schedule",
    "href": "2025/sessions/day3/index.html#schedule",
    "title": "Day 3: Multiword Units and Collocations",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nTime\nActivity\n\n\n\n\n10:30-12:00\nSession 7: Multiword Units ‚Äî Conceptual Overview\n\n\n12:00-13:00\nLunch\n\n\n13:00-14:30\nSession 8: Hands-on Collocation Analysis\n\n\n14:30-14:40\nBreak\n\n\n14:40-16:10\nSession 9: Learner Corpus Mini-Research",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Day 3: Multiword Units and Collocations"
    ]
  },
  {
    "objectID": "2025/sessions/day3/index.html#assignments",
    "href": "2025/sessions/day3/index.html#assignments",
    "title": "Day 3: Multiword Units and Collocations",
    "section": "Assignments",
    "text": "Assignments\n\nDue Tomorrow: Hands-on Assignment 3\nPrepare mini-project research topic and questions for presentation",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Day 3: Multiword Units and Collocations"
    ]
  },
  {
    "objectID": "2025/sessions/day3/index.html#reflection",
    "href": "2025/sessions/day3/index.html#reflection",
    "title": "Day 3: Multiword Units and Collocations",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Day 3: Multiword Units and Collocations"
    ]
  },
  {
    "objectID": "2025/sessions/day4/session12.html#learning-objectives",
    "href": "2025/sessions/day4/session12.html#learning-objectives",
    "title": "Session 12",
    "section": "üéØ Learning Objectives",
    "text": "üéØ Learning Objectives\n\nBy the end of this session, students will be able to:\n\nConduct linguistic complexity analysis using a template Python code provided by the instructor.\n(Optional) Apply the concept of linguistic complexity to the Japanese language.",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Session 12"
    ]
  },
  {
    "objectID": "2025/sessions/day4/session12.html#required-readings",
    "href": "2025/sessions/day4/session12.html#required-readings",
    "title": "Session 12",
    "section": "üìö Required Readings",
    "text": "üìö Required Readings\n\nKyle, K., & Crossley, S. A. (2018). Measuring Syntactic Complexity in L2 Writing Using Fine‚ÄêGrained Clausal and Phrasal Indices. The Modern Language Journal, 102(2), 333‚Äì349. https://doi.org/10.1111/modl.12468",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Session 12"
    ]
  },
  {
    "objectID": "2025/sessions/day4/session12.html#recommended-readings",
    "href": "2025/sessions/day4/session12.html#recommended-readings",
    "title": "Session 12",
    "section": "Recommended Readings",
    "text": "Recommended Readings\n\nKyle, K., & Crossley, S. (2017). Assessing syntactic sophistication in L2 writing: A usage-based approach. Language Testing, 34(4), 513‚Äì535. https://doi.org/10.1177/0265532217712554\nKyle, K., Choe, A. T., Eguchi, M., LaFlair, G., & Ziegler, N. (2021). A Comparison of Spoken and Written Language Use in Traditional and Technology‚ÄêMediated Learning Environments. ETS Research Report Series, 2021(1), 1‚Äì29. https://doi.org/10.1002/ets2.12329",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Session 12"
    ]
  },
  {
    "objectID": "2025/sessions/day4/session12.html#tools-used",
    "href": "2025/sessions/day4/session12.html#tools-used",
    "title": "Session 12",
    "section": "üõ†Ô∏è Tools Used",
    "text": "üõ†Ô∏è Tools Used\n\nTagAnt\nSimple Text Analyzer: A web app created for you.",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Session 12"
    ]
  },
  {
    "objectID": "2025/sessions/day4/session12.html#materials",
    "href": "2025/sessions/day4/session12.html#materials",
    "title": "Session 12",
    "section": "Materials",
    "text": "Materials\n\nSlides (Under construction)",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Session 12"
    ]
  },
  {
    "objectID": "2025/sessions/day4/session12.html#reflection",
    "href": "2025/sessions/day4/session12.html#reflection",
    "title": "Session 12",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Session 12"
    ]
  },
  {
    "objectID": "2025/sessions/day4/session10.html#learning-objectives",
    "href": "2025/sessions/day4/session10.html#learning-objectives",
    "title": "Session 10",
    "section": "üéØ Learning Objectives",
    "text": "üéØ Learning Objectives\n\nBy the end of this session, students will be able to:\n\nUnderstand different approaches to grammatical features:\n\nGrammatical complexity research\nDescriptive approaches\n\nUnderstand historical overview of the syntactic complexity research\nUnderstand current trends of syntactic complexity research",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Session 10"
    ]
  },
  {
    "objectID": "2025/sessions/day4/session10.html#key-concepts",
    "href": "2025/sessions/day4/session10.html#key-concepts",
    "title": "Session 10",
    "section": "üîë Key Concepts",
    "text": "üîë Key Concepts\n\nGrammatical complexity\nPredictive measures versus Descriptive measures\n\n\nüìö Required Readings\n\nDurrant Ch. 5.\n\n\n\nRecommended Readings\n\nBiber, D., Gray, B., Staples, S., & Egbert, J. (2020). Investigating grammatical complexity in L2 English writing research: Linguistic description versus predictive measurement. Journal of English for Academic Purposes, 46, 100869. https://doi.org/10.1016/j.jeap.2020.100869",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Session 10"
    ]
  },
  {
    "objectID": "2025/sessions/day4/session10.html#materials",
    "href": "2025/sessions/day4/session10.html#materials",
    "title": "Session 10",
    "section": "Materials",
    "text": "Materials\n\nSlides (Under construction)",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Session 10"
    ]
  },
  {
    "objectID": "2025/sessions/day4/session10.html#reflection",
    "href": "2025/sessions/day4/session10.html#reflection",
    "title": "Session 10",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Session 10"
    ]
  },
  {
    "objectID": "2025/syllabus/schedule.html",
    "href": "2025/syllabus/schedule.html",
    "title": "Course Schedule",
    "section": "",
    "text": "This course covers foundational concepts in corpus linguistics, corpus analysis methods, and their research applications across the following four areas: vocabulary, multiword units, and grammar.\n\n\n\nDay\nSession No.\nSession title\n\n\n\n\nDay 1 (Aug.¬†2nd, Sat)\n\nIntroduction to Corpus Linguistics\n\n\n\nSession 1\nGetting Started with Corpus Linguistics\n\n\n\nSession 2\nFoundations of Corpus Linguistics\n\n\n\nSession 3\nBasic Corpus Search\n\n\nDay 2 (Aug.¬†4th, Mon)\n\nAnalyzing Vocabulary\n\n\n\nSession 4\nConceptual overview\n\n\n\nSession 5\nFrequency lists & Lexical profiling\n\n\n\nSession 6\nLexical diversity & Sophistication\n\n\nDay 3 (Aug.¬†5th, Tue)\n\nAnalyzing Multiword Units\n\n\n\nSession 7\nConceptual overview\n\n\n\nSession 8\nCollocations & N-grams\n\n\n\nSession 9\nMini-research & Final project overview\n\n\nDay 4 (Aug.¬†6th, Wed)\n\nAnalyzing Grammar\n\n\n\nSession 10\nConceptual overview\n\n\n\nSession 11\nPOS-tagging and Dependency Parsing\n\n\n\nSession 12\nSyntactic Complexity\n\n\nDay 5 (Aug.¬†7th, Thu)\n\nAdvanced Topics & Wrap-up\n\n\n\nSession 13\nUsing large language models for language annotation\n\n\n\nSession 14\nFinal project preparation time\n\n\n\nSession 15\nFinal project presentation",
    "crumbs": [
      "Syllabus",
      "Course Schedule"
    ]
  },
  {
    "objectID": "2025/syllabus/schedule.html#overview",
    "href": "2025/syllabus/schedule.html#overview",
    "title": "Course Schedule",
    "section": "",
    "text": "This course covers foundational concepts in corpus linguistics, corpus analysis methods, and their research applications across the following four areas: vocabulary, multiword units, and grammar.\n\n\n\nDay\nSession No.\nSession title\n\n\n\n\nDay 1 (Aug.¬†2nd, Sat)\n\nIntroduction to Corpus Linguistics\n\n\n\nSession 1\nGetting Started with Corpus Linguistics\n\n\n\nSession 2\nFoundations of Corpus Linguistics\n\n\n\nSession 3\nBasic Corpus Search\n\n\nDay 2 (Aug.¬†4th, Mon)\n\nAnalyzing Vocabulary\n\n\n\nSession 4\nConceptual overview\n\n\n\nSession 5\nFrequency lists & Lexical profiling\n\n\n\nSession 6\nLexical diversity & Sophistication\n\n\nDay 3 (Aug.¬†5th, Tue)\n\nAnalyzing Multiword Units\n\n\n\nSession 7\nConceptual overview\n\n\n\nSession 8\nCollocations & N-grams\n\n\n\nSession 9\nMini-research & Final project overview\n\n\nDay 4 (Aug.¬†6th, Wed)\n\nAnalyzing Grammar\n\n\n\nSession 10\nConceptual overview\n\n\n\nSession 11\nPOS-tagging and Dependency Parsing\n\n\n\nSession 12\nSyntactic Complexity\n\n\nDay 5 (Aug.¬†7th, Thu)\n\nAdvanced Topics & Wrap-up\n\n\n\nSession 13\nUsing large language models for language annotation\n\n\n\nSession 14\nFinal project preparation time\n\n\n\nSession 15\nFinal project presentation",
    "crumbs": [
      "Syllabus",
      "Course Schedule"
    ]
  },
  {
    "objectID": "2025/syllabus/schedule.html#final-project",
    "href": "2025/syllabus/schedule.html#final-project",
    "title": "Course Schedule",
    "section": "Final Project",
    "text": "Final Project\nFinal Project: Guidelines - Due 2 weeks after course",
    "crumbs": [
      "Syllabus",
      "Course Schedule"
    ]
  },
  {
    "objectID": "2025/syllabus/schedule.html#important-notes",
    "href": "2025/syllabus/schedule.html#important-notes",
    "title": "Course Schedule",
    "section": "Important Notes",
    "text": "Important Notes\n\nAll times are Japan Standard Time (JST)\nBring your laptop to all sessions\nComplete readings before each day (see Readings)\n\nFinal Project: Guidelines - Due 2 weeks after course",
    "crumbs": [
      "Syllabus",
      "Course Schedule"
    ]
  },
  {
    "objectID": "2025/slides/session-7.html#objectives",
    "href": "2025/slides/session-7.html#objectives",
    "title": "Session 7: Multiword Units",
    "section": "Objectives",
    "text": "Objectives"
  },
  {
    "objectID": "2025/slides/session-5.html#objectives",
    "href": "2025/slides/session-5.html#objectives",
    "title": "Session 5: Hands-on activity #2",
    "section": "Objectives",
    "text": "Objectives\n\nCompute frequency of a single-word lexical item in reference corpora\nDerive vocabulary frequency list using concordancing software (e.g., AntConc)\nApply tokenization on the Japanese language corpus for frequency analysis\nConduct Lexical Profiling using a web-application or desktop application (e.g., AntWordProfiler)"
  },
  {
    "objectID": "2025/slides/session-5.html#antconc",
    "href": "2025/slides/session-5.html#antconc",
    "title": "Session 5: Hands-on activity #2",
    "section": "AntConc",
    "text": "AntConc\n\nAntConc is free concordancing tool.\nDeveloped by Laurence ANTHONY."
  },
  {
    "objectID": "2025/slides/session-5.html#task-1-loading-a-corpus-to-antconc",
    "href": "2025/slides/session-5.html#task-1-loading-a-corpus-to-antconc",
    "title": "Session 5: Hands-on activity #2",
    "section": "Task 1: Loading a corpus to AntConc",
    "text": "Task 1: Loading a corpus to AntConc"
  },
  {
    "objectID": "2025/slides/session-5.html#open-antconc",
    "href": "2025/slides/session-5.html#open-antconc",
    "title": "Session 5: Hands-on activity #2",
    "section": "Open AntConc",
    "text": "Open AntConc\n\nAntConc"
  },
  {
    "objectID": "2025/slides/session-5.html#antconc-window",
    "href": "2025/slides/session-5.html#antconc-window",
    "title": "Session 5: Hands-on activity #2",
    "section": "AntConc window",
    "text": "AntConc window\n\nAntConc2"
  },
  {
    "objectID": "2025/slides/session-5.html#load-a-corpus",
    "href": "2025/slides/session-5.html#load-a-corpus",
    "title": "Session 5: Hands-on activity #2",
    "section": "Load a corpus",
    "text": "Load a corpus\nNow, let‚Äôs load a corpus.\n\nLoad-corpus"
  },
  {
    "objectID": "2025/slides/session-5.html#task-2-creating-a-frequency-list",
    "href": "2025/slides/session-5.html#task-2-creating-a-frequency-list",
    "title": "Session 5: Hands-on activity #2",
    "section": "Task 2: Creating a frequency list",
    "text": "Task 2: Creating a frequency list"
  },
  {
    "objectID": "2025/slides/session-5.html#keyword",
    "href": "2025/slides/session-5.html#keyword",
    "title": "Session 5: Hands-on activity #2",
    "section": "Keyword",
    "text": "Keyword\nLet‚Äôs now create a frequency list\n\nSelect Keyword analysis option\nSet Min. Freq and Min. Range\n\n\nMin. Freq = the number of times the word should occur in the corpus\nMin. Range = the number of files in which the word should occur\n\n\nHit Start"
  },
  {
    "objectID": "2025/slides/session-5.html#task-3-vocabulary-profiling-through-lextutor",
    "href": "2025/slides/session-5.html#task-3-vocabulary-profiling-through-lextutor",
    "title": "Session 5: Hands-on activity #2",
    "section": "Task 3: Vocabulary Profiling through LexTutor",
    "text": "Task 3: Vocabulary Profiling through LexTutor\nNow that we understand an important property of language (Zipf‚Äôs law), let‚Äôs conduct lexical profiling.\n\nVisit our simple-text-analyzer tool.\nHit Frequency analysis and upload the frequency list."
  },
  {
    "objectID": "2025/slides/session-5.html#task-4-vocabulary-profiling-through-antwordprofiler",
    "href": "2025/slides/session-5.html#task-4-vocabulary-profiling-through-antwordprofiler",
    "title": "Session 5: Hands-on activity #2",
    "section": "Task 4: Vocabulary Profiling through AntWordProfiler",
    "text": "Task 4: Vocabulary Profiling through AntWordProfiler"
  },
  {
    "objectID": "2025/slides/session-5.html#task-5-tokenizing-non-english-language-using-tagant",
    "href": "2025/slides/session-5.html#task-5-tokenizing-non-english-language-using-tagant",
    "title": "Session 5: Hands-on activity #2",
    "section": "Task 5: Tokenizing Non-English language using TagAnt",
    "text": "Task 5: Tokenizing Non-English language using TagAnt"
  },
  {
    "objectID": "2025/slides/coca_table.html",
    "href": "2025/slides/coca_table.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenre\n# texts\n# words\nExplanation\n\n\n\n\nSpoken\n44,803\n127,396,932\nTranscripts of unscripted conversation from more than 150 different TV and radio programs (examples: All Things Considered (NPR), Newshour (PBS), Good Morning America (ABC), Oprah)\n\n\nFiction\n25,992\n119,505,305\nShort stories and plays from literary magazines, children‚Äôs magazines, popular magazines, first chapters of first edition books 1990-present, and fan fiction.\n\n\nMagazines\n86,292\n127,352,030\nNearly 100 different magazines, with a good mix between specific domains like news, health, home and gardening, women, financial, religion, sports, etc.\n\n\nNewspapers\n90,243\n122,958,016\nNewspapers from across the US, including: USA Today, New York Times, Atlanta Journal Constitution, San Francisco Chronicle, etc. Good mix between different sections of the newspaper, such as local news, opinion, sports, financial, etc.\n\n\nAcademic\n26,137\n120,988,361\nMore than 200 different peer-reviewed journals. These cover the full range of academic disciplines, with a good balance among education, social sciences, history, humanities, law, medicine, philosophy/religion, science/technology, and business\n\n\nWeb (Genl)\n88,989\n129,899,427\nClassified into the web genres of academic, argument, fiction, info, instruction, legal, news, personal, promotion, review web pages (by Serge Sharoff). Taken from the US portion of the GloWbE corpus.\n\n\nWeb (Blog)\n98,748\n125,496,216\nTexts that were classified by Google as being blogs. Further classified into the web genres of academic, argument, fiction, info, instruction, legal, news, personal, promotion, review web pages. Taken from the US portion of the GloWbE corpus.\n\n\nTV/Movies\n23,975\n129,293,467\nSubtitles from OpenSubtitles.org, and later the TV and Movies corpora. Studies have shown that the language from these shows and movies is even more colloquial / core than the data in actual ‚Äúspoken corpora‚Äù.\n\n\nTotal\n485,179\n1,002,889,754"
  },
  {
    "objectID": "2025/slides/session-6.html#objectives",
    "href": "2025/slides/session-6.html#objectives",
    "title": "Session 6: Hands-on activity #3",
    "section": "Objectives",
    "text": "Objectives\nBy the end of this session, you will be able to:\n\nCompute simple lexical diversity measures using spreadsheet software and dedicated tool\nExplain how modern lexical diversity measures are calculated\nCompute simple lexical sophistication measures"
  },
  {
    "objectID": "2025/slides/session-6.html#terminology",
    "href": "2025/slides/session-6.html#terminology",
    "title": "Session 6: Hands-on activity #3",
    "section": "Terminology",
    "text": "Terminology\nIn this presentation, I will use the following terms:\n\nInput text: The text you want to analyze (e.g., learner produce text)."
  },
  {
    "objectID": "2025/slides/session-6.html#lexical-diversity",
    "href": "2025/slides/session-6.html#lexical-diversity",
    "title": "Session 6: Hands-on activity #3",
    "section": "Lexical Diversity",
    "text": "Lexical Diversity\n\nLexical Diversity is computed internally to text.\ne.g., Type-Token Ratio:\n\nCount the number of unique word (Type) in the input text\nCount the number of total word (Token) in the input text\nDevide Type by token."
  },
  {
    "objectID": "2025/slides/session-6.html#lexical-sophistication",
    "href": "2025/slides/session-6.html#lexical-sophistication",
    "title": "Session 6: Hands-on activity #3",
    "section": "Lexical Sophistication",
    "text": "Lexical Sophistication\n\nLexical Sophistication requires external resources to compute.\nTo derive a frequency index:\n\nCompile a frequency list\nFor each word in the input text, retrieve frequency score from the list\n\ne.g., tree ‚Äì&gt; 1,0000\n\nAverage the frequency scores (out of item awarded the score)"
  },
  {
    "objectID": "2025/slides/session-6.html#computing-simple-lexical-diversity-measures-by-hand",
    "href": "2025/slides/session-6.html#computing-simple-lexical-diversity-measures-by-hand",
    "title": "Session 6: Hands-on activity #3",
    "section": "Computing simple Lexical Diversity measures by hand",
    "text": "Computing simple Lexical Diversity measures by hand"
  },
  {
    "objectID": "2025/slides/session-6.html#simple-text-example",
    "href": "2025/slides/session-6.html#simple-text-example",
    "title": "Session 6: Hands-on activity #3",
    "section": "Simple Text Example",
    "text": "Simple Text Example\nCound the type and token of the following texts.\n\n\n\n\n\n\n\nID\nText\n\n\n\n\nText 1\n‚ÄúThe dog ran. The dog jumped. The dog played. The dog barked. The dog ran again and jumped again.‚Äù\n\n\nText 2\n‚ÄúA curious fox trotted briskly through the meadow, leaping over mossy logs, sniffing wildflowers, and vanishing into golden twilight.‚Äù\n\n\n\nNote : Texts were generated by GPT for illustration purposes."
  },
  {
    "objectID": "2025/slides/session-6.html#simple-text-example-1",
    "href": "2025/slides/session-6.html#simple-text-example-1",
    "title": "Session 6: Hands-on activity #3",
    "section": "Simple Text Example",
    "text": "Simple Text Example\n\n\n\n\n\n\n\n\n\nID\nText\nToken\nType\n\n\n\n\nText 1\n‚ÄúThe dog ran. The dog jumped. The dog played. The dog barked. The dog ran again and jumped again.‚Äù\n19\n8\n\n\nText 2\n‚ÄúA curious fox trotted briskly through the meadow, leaping over mossy logs, sniffing wildflowers, and vanishing into golden twilight.‚Äù\n19\n19\n\n\n\nNote : Texts were generated by GPT for illustration purposes."
  },
  {
    "objectID": "2025/slides/session-6.html#impact-of-text-lengths",
    "href": "2025/slides/session-6.html#impact-of-text-lengths",
    "title": "Session 6: Hands-on activity #3",
    "section": "Impact of Text lengths",
    "text": "Impact of Text lengths\n\n\n\n\n\n\n\n\n\n\nID\nText\nToken\nType\n\n\n\n\nText 1a\n‚ÄúThe dog ran. The dog jumped. The dog played. The dog barked. The dog ran again and jumped again.‚Äù\n19\n8\n\n\nText 1b\n‚ÄúThe dog ran. The dog jumped. The dog barked. The dog played. The dog ran quickly. The dog jumped so high. The dog barked very loudly. The dog played, sat, and rolled. The dog sneezed. The dog ate the food.‚Äù\n40\n18\n\n\nText 1c\n‚ÄúThe parrot squawked loudly. The parrot chirped again. A toucan perched nearby. The parrot fluttered. Wings flapped softly. The parrot chirped again. Feathers shimmered under sunlight. The crow cawed. The parrot glided low. The air shimmered. The owl blinked slowly. The parrot perched again. The owl blinked slowly. The parrot shrieked. The parrot chirped nearby again. The parrot squawked again.‚Äù\n60\n27\n\n\n\nNote : Texts were generated by GPT for illustration purposes."
  },
  {
    "objectID": "2025/slides/session-6.html#lets-calculate-some-classical-lexical-diversity-indices",
    "href": "2025/slides/session-6.html#lets-calculate-some-classical-lexical-diversity-indices",
    "title": "Session 6: Hands-on activity #3",
    "section": "Let‚Äôs calculate some classical Lexical Diversity indices",
    "text": "Let‚Äôs calculate some classical Lexical Diversity indices\n\nOpen Google Spreadsheet\nCalculate the lexical diversity indices on the next page."
  },
  {
    "objectID": "2025/slides/session-6.html#some-classic-lexical-diversity",
    "href": "2025/slides/session-6.html#some-classic-lexical-diversity",
    "title": "Session 6: Hands-on activity #3",
    "section": "Some classic lexical diversity",
    "text": "Some classic lexical diversity\nWe calculate this for illustration but NEVER use these in your study.\n\n\\(TTR = {nType \\over nToken}\\)\n\\(RootTTR = {nType \\over \\sqrt{nToken}}\\)\n\\(LogTTR = {\\log(nType) \\over \\log(nToken)}\\)\n\\(Maas = {\\log(nTokens) - \\log(nTypes) \\over \\log(nToken)^2}\\)"
  },
  {
    "objectID": "2025/slides/session-6.html#what-should-we-actually-use-then",
    "href": "2025/slides/session-6.html#what-should-we-actually-use-then",
    "title": "Session 6: Hands-on activity #3",
    "section": "What should we actually use then?",
    "text": "What should we actually use then?\n\nThe Measure of Textual Lexical Diversity (MTLD)\nMoving-Average Type Token Ratio (MATTR)\n\n‚Üí These are shown as more robust indices of LD."
  },
  {
    "objectID": "2025/slides/session-6.html#using-taaled-desktop-version",
    "href": "2025/slides/session-6.html#using-taaled-desktop-version",
    "title": "Session 6: Hands-on activity #3",
    "section": "Using TAALED desktop version",
    "text": "Using TAALED desktop version\n\nWe can use Tool for the Automatic Analysis of Lexical Diversity (TAALED)\nDownload it to your computer and we will use it to compute modern LD measures\n\n\nTAALED"
  },
  {
    "objectID": "2025/slides/session-6.html#setting-up",
    "href": "2025/slides/session-6.html#setting-up",
    "title": "Session 6: Hands-on activity #3",
    "section": "Setting up",
    "text": "Setting up\n\nClick the software icon after download\nFor mac users, the system will issue warning, you must follow the following step:\n\nGo to setting and select Privacy & Security\nIf you have already attempted to open the software, there will be Open Anyway button.\nClick Open Anyway and that will allow Mac to open the software."
  },
  {
    "objectID": "2025/slides/session-6.html#selecting-indics",
    "href": "2025/slides/session-6.html#selecting-indics",
    "title": "Session 6: Hands-on activity #3",
    "section": "Selecting indics",
    "text": "Selecting indics\nYou can then wait for the TAALED app to start up.\n\nTAALED"
  },
  {
    "objectID": "2025/slides/session-6.html#options",
    "href": "2025/slides/session-6.html#options",
    "title": "Session 6: Hands-on activity #3",
    "section": "Options",
    "text": "Options\nWord analysis options\n\nAll words: Conduct analysis including all words.\nContent words: Conduct analysis with content words only.\nFunction words: Conduct analysis with function words only."
  },
  {
    "objectID": "2025/slides/session-6.html#options-1",
    "href": "2025/slides/session-6.html#options-1",
    "title": "Session 6: Hands-on activity #3",
    "section": "Options",
    "text": "Options\nIndex selection\nSelect the indices you need in the results. Three variants of MTLD are available.\n\nMTLD Original:\nMTLD MA Bi: Moving Average Bidirectional\nMTLD MA Wrap: If there is words left in the final factor, come back to the first part and complete the analysis."
  },
  {
    "objectID": "2025/slides/session-6.html#options-2",
    "href": "2025/slides/session-6.html#options-2",
    "title": "Session 6: Hands-on activity #3",
    "section": "Options",
    "text": "Options\nInput and output options\n\nYou can choose the input folder by selection\n\nOutput option\n\nTicking the Individual Item Output button allows you to have POS analysis\n\nparent_cw_nn\nand_fw\nteacher_cw_nn\ndisagree_cw_vb\nthat_fw"
  },
  {
    "objectID": "2025/slides/session-6.html#run-the-analysis",
    "href": "2025/slides/session-6.html#run-the-analysis",
    "title": "Session 6: Hands-on activity #3",
    "section": "Run the analysis",
    "text": "Run the analysis\n\nPress Process Texts and wait the following display.\n\n\nAnalysis complete"
  },
  {
    "objectID": "2025/slides/session-6.html#lets-take-a-look-at-the-csv-file",
    "href": "2025/slides/session-6.html#lets-take-a-look-at-the-csv-file",
    "title": "Session 6: Hands-on activity #3",
    "section": "Let‚Äôs take a look at the csv file",
    "text": "Let‚Äôs take a look at the csv file\n\nWhat‚Äôs CSV?\n\nCSV (Comma Separated Values) file is a file extension like others (txt, docx).\nIt allows table like representation of data (like excel) separated by comma.\n\n\nThe Raw data (if you open it with text editor) should look like the following:\nfilename,basic_ntokens,basic_ntypes,basic_ncontent_tokens,basic_ncontent_types,basic_nfunction_tokens,basic_nfunction_types,lexical_density_types,lexical_density_tokens,maas_ttr_aw,mattr50_aw,hdd42_aw,mtld_original_aw,mtld_ma_bi_aw,mtld_ma_wrap_aw\nW_CHN_PTJ0_004_B1_2_ORIG.txt,267,124,135,75,132,49,0.6048387096774194,0.5056179775280899,0.056571333957257205,0.7793577981651377,0.7981161136859327,68.68659119235562,65.84622666144406,61.50561797752809\nW_JPN_SMK0_015_B1_2_ORIG.txt,302,138,129,82,173,56,0.5942028985507246,0.4271523178807947,0.05530143602594381,0.777865612648221,0.7974803670481457,68.38677597714803,67.6645170484911,65.22185430463576"
  },
  {
    "objectID": "2025/slides/session-6.html#opening-csv-file-in-a-spreadsheet-software",
    "href": "2025/slides/session-6.html#opening-csv-file-in-a-spreadsheet-software",
    "title": "Session 6: Hands-on activity #3",
    "section": "Opening csv file in a spreadsheet software",
    "text": "Opening csv file in a spreadsheet software\n\nYou can open csv file in Excel (or any other spreadsheet software)"
  },
  {
    "objectID": "2025/slides/session-6.html#questions",
    "href": "2025/slides/session-6.html#questions",
    "title": "Session 6: Hands-on activity #3",
    "section": "Questions?",
    "text": "Questions?"
  },
  {
    "objectID": "2025/slides/session-6.html#lemmatize",
    "href": "2025/slides/session-6.html#lemmatize",
    "title": "Session 6: Hands-on activity #3",
    "section": "Lemmatize?",
    "text": "Lemmatize?\n\nWhat do you think is the effect of lemmatization on the lexical diversity measures?\nShould we lemmatize? Why or why not?"
  },
  {
    "objectID": "2025/slides/session-6.html#computing-simple-lexical-sophisitcation-measures",
    "href": "2025/slides/session-6.html#computing-simple-lexical-sophisitcation-measures",
    "title": "Session 6: Hands-on activity #3",
    "section": "Computing simple Lexical Sophisitcation measures",
    "text": "Computing simple Lexical Sophisitcation measures"
  },
  {
    "objectID": "2025/slides/session-6.html#lexical-sophistication-1",
    "href": "2025/slides/session-6.html#lexical-sophistication-1",
    "title": "Session 6: Hands-on activity #3",
    "section": "Lexical sophistication",
    "text": "Lexical sophistication\nThere are a number of lexical sophistication measures for English (+ 300).\n\n12 categories of measures (Eguchi & Kyle, 2020)\n\nFrequency\nRange\nPsycholinguistic Norm"
  },
  {
    "objectID": "2025/slides/session-6.html#typical-operationalization",
    "href": "2025/slides/session-6.html#typical-operationalization",
    "title": "Session 6: Hands-on activity #3",
    "section": "Typical operationalization",
    "text": "Typical operationalization\n\nOperationalization means\nTypically, lexical sophistication (LS) is calculated as an average:\nTypical LS score = \\[Total \\; LS \\; score \\over nToken \\; with \\; LS \\; score\\]\nAverage is just a convenient choice."
  },
  {
    "objectID": "2025/slides/session-6.html#using-an-emulation-of-taales",
    "href": "2025/slides/session-6.html#using-an-emulation-of-taales",
    "title": "Session 6: Hands-on activity #3",
    "section": "Using an emulation of TAALES",
    "text": "Using an emulation of TAALES\n\nSince the desktop version of TAALES is unstable these days, we will use a simple web application."
  },
  {
    "objectID": "2025/syllabus/index.html",
    "href": "2025/syllabus/index.html",
    "title": "Course Syllabus",
    "section": "",
    "text": "Course Title: Linguistic Data Analysis I\nCredits: 2\nFormat: Intensive 5-day course (15 sessions)\nLanguage: English\n Classroom: 113 Lecture room ‚ë£",
    "crumbs": [
      "Syllabus",
      "Course Syllabus"
    ]
  },
  {
    "objectID": "2025/syllabus/index.html#course-information",
    "href": "2025/syllabus/index.html#course-information",
    "title": "Course Syllabus",
    "section": "",
    "text": "Course Title: Linguistic Data Analysis I\nCredits: 2\nFormat: Intensive 5-day course (15 sessions)\nLanguage: English\n Classroom: 113 Lecture room ‚ë£",
    "crumbs": [
      "Syllabus",
      "Course Syllabus"
    ]
  },
  {
    "objectID": "2025/syllabus/index.html#instructor-information",
    "href": "2025/syllabus/index.html#instructor-information",
    "title": "Course Syllabus",
    "section": "Instructor Information",
    "text": "Instructor Information\nInstructor: Masaki Eguchi, Ph.D.",
    "crumbs": [
      "Syllabus",
      "Course Syllabus"
    ]
  },
  {
    "objectID": "2025/syllabus/index.html#course-description",
    "href": "2025/syllabus/index.html#course-description",
    "title": "Course Syllabus",
    "section": "Course Description",
    "text": "Course Description\nThis course introduces the foundations of corpus linguistics and the analysis of learner language through corpus linguistic approaches. It covers key concepts in corpus linguistics, including what corpora are, how they are used to answer (applied) linguistic research questions, and how to design corpus-based analyses to address substantive research questions in second language research. The primary language of analysis in this course is English, but students are encouraged to apply the concepts introduced to the languages they work with in their own research.",
    "crumbs": [
      "Syllabus",
      "Course Syllabus"
    ]
  },
  {
    "objectID": "2025/syllabus/index.html#learning-objectives",
    "href": "2025/syllabus/index.html#learning-objectives",
    "title": "Course Syllabus",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this course, students will be able to:\n\nExplain what corpus linguistics is and how corpus linguistics can help learn linguistic phenomena\nSearch for and select available corpora relevant to their own research\nDiscuss design issues related to language corpora for specific research purposes\nApply introductory corpus linguistic analyses (e.g., frequency analysis, concordancing, POS tagging) to preprocessed corpora\nEvaluate the benefits and drawbacks of a corpus linguistic approach to linguistic analysis",
    "crumbs": [
      "Syllabus",
      "Course Syllabus"
    ]
  },
  {
    "objectID": "2025/syllabus/index.html#course-components",
    "href": "2025/syllabus/index.html#course-components",
    "title": "Course Syllabus",
    "section": "Course Components",
    "text": "Course Components\n\n\n\n\n\n\nNavigation\n\n\n\n\nüìÖ Detailed Schedule",
    "crumbs": [
      "Syllabus",
      "Course Syllabus"
    ]
  },
  {
    "objectID": "2025/syllabus/index.html#required-materials",
    "href": "2025/syllabus/index.html#required-materials",
    "title": "Course Syllabus",
    "section": "Required Materials",
    "text": "Required Materials\n\nTextbook\n\nDurrant, P. (2023). Corpus linguistics for writing development: A guide for research. Routledge. https://doi.org/10.4324/9781003152682\nStefanowitsch, A. (2020). Corpus linguistics: A guide to the methodology. Zenodo. https://doi.org/10.5281/ZENODO.3735822 (This is an open source textbook, so it‚Äôs freely available online)\n\nOther required/Optional readings are provided through Google Classroom.\n\n\nSoftwares (Free)\n\nConcordancing Software\n\nAntConc: Corpus analysis toolkit for Concordancing\n\n\n\nLexical Profiling Software\n\nAntWordProfiler: Corpus analysis toolkit for Lexical Profiling\nLexTutor: Corpus analysis toolkit online\n\n\n\nStatistics\n\nJASP: Statistical analysis software\n\n\n\nOthers\n\nGoogle Account: For Colab notebooks (insert link here)\nText Editor: VS Code recommended\nSimple Text Analyzer: A web app created for you.",
    "crumbs": [
      "Syllabus",
      "Course Syllabus"
    ]
  },
  {
    "objectID": "2025/syllabus/index.html#assignments-and-grading",
    "href": "2025/syllabus/index.html#assignments-and-grading",
    "title": "Course Syllabus",
    "section": "Assignments and Grading",
    "text": "Assignments and Grading\nYou can find detailed information about each assignment in assignments page (under construction).\n\nGrade Distribution\n\n\n\nAssignment\n\nPercent\n\n\n\n\nHands-on Assignments\n(4 √ó 15%)\n60%\n\n\nClass Participation\n\n20%\n\n\nFinal Project\n\n20%\n\n\n\n\n\nGrading Scale\nWe follow the grading system at Tohoku University.\n\n\n\nGrade\nRange\nGrade Point\n\n\n\n\nAA\n100-90%\n4.0\n\n\nA\n89-80%\n3.0\n\n\nB\n79-70%\n2.0\n\n\nC\n69-60%\n1.0\n\n\nD\n59-0%\n0.0",
    "crumbs": [
      "Syllabus",
      "Course Syllabus"
    ]
  },
  {
    "objectID": "2025/syllabus/index.html#daily-structure",
    "href": "2025/syllabus/index.html#daily-structure",
    "title": "Course Syllabus",
    "section": "Daily Structure",
    "text": "Daily Structure\nEach day follows this general pattern:\n\n\n\nTime\nActivity\n\n\n\n\n10:30-12:00\nSession 1\n\n\n12:00-13:00\nLunch break\n\n\n13:00-14:30\nSession 2\n\n\n14:30-14:40\nBreak\n\n\n14:40-16:10\nSession 3",
    "crumbs": [
      "Syllabus",
      "Course Syllabus"
    ]
  },
  {
    "objectID": "2025/syllabus/index.html#attendance-policy",
    "href": "2025/syllabus/index.html#attendance-policy",
    "title": "Course Syllabus",
    "section": "Attendance Policy",
    "text": "Attendance Policy\n\nDue to the intensive nature of the course, attendance and participation are crucial to your success in this course.\nHowever, in case of emergency, do not hesitate to reach out to the instructor for possible accomodation. I may be able to accommodate depending on the situation.",
    "crumbs": [
      "Syllabus",
      "Course Syllabus"
    ]
  },
  {
    "objectID": "2025/syllabus/index.html#assignment-submission",
    "href": "2025/syllabus/index.html#assignment-submission",
    "title": "Course Syllabus",
    "section": "Assignment Submission",
    "text": "Assignment Submission\n\nDeadlines\n\nAll assignments are due at 10:30 AM on the specified day\nLate submissions will receive a 10% penalty per day\nExtensions may be granted for documented emergencies.\n\n\n\nSubmission Format\n\nSubmit all assignments via the course management system (Google Classroom)\nUse the provided templates when available\nFile naming convention: LastName_Assignment#.ext\nAcceptable formats: .docx, .pdf, .ipynb (for Python notebooks)\n\n\n\nPlagiarism\n\n\nCollaboration",
    "crumbs": [
      "Syllabus",
      "Course Syllabus"
    ]
  },
  {
    "objectID": "2025/syllabus/index.html#technology-policy",
    "href": "2025/syllabus/index.html#technology-policy",
    "title": "Course Syllabus",
    "section": "Technology Policy",
    "text": "Technology Policy\n\nRequired Technology\n\nBring a laptop to every session.\nEnsure all required software is installed.\n\n\n\nClassroom Etiquette\n\nLaptops should be used for course activities only",
    "crumbs": [
      "Syllabus",
      "Course Syllabus"
    ]
  },
  {
    "objectID": "2025/syllabus/index.html#communication",
    "href": "2025/syllabus/index.html#communication",
    "title": "Course Syllabus",
    "section": "Communication",
    "text": "Communication\n\nCourse related communications will happen via Google Classroom.\n\n\nCourse Announcements\n\nCourse announcements are made through Google Classroom.\n\n\n\nMaterials Sharing\n\nMaterials (e.g., slides) are shared through this website.",
    "crumbs": [
      "Syllabus",
      "Course Syllabus"
    ]
  },
  {
    "objectID": "2025/syllabus/index.html#accommodations",
    "href": "2025/syllabus/index.html#accommodations",
    "title": "Course Syllabus",
    "section": "Accommodations",
    "text": "Accommodations",
    "crumbs": [
      "Syllabus",
      "Course Syllabus"
    ]
  },
  {
    "objectID": "2025/sessions/day4/session11.html#learning-objectives",
    "href": "2025/sessions/day4/session11.html#learning-objectives",
    "title": "Session 11",
    "section": "üéØ Learning Objectives",
    "text": "üéØ Learning Objectives\n\nBy the end of this session, students will be able to:\n\nUnderstand NLP tasks such as POS tagging and dependency parsing\nUnderstand how automated parsing works\nConduct POS tagging using spaCy library in Python (through Google Colab)\nConduct Dependency parsing using spaCy library in Python (through Google Colab)\nConduct multi-lingual Part-Of-Speech (POS) tagging using TagAnt",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Session 11"
    ]
  },
  {
    "objectID": "2025/sessions/day4/session11.html#key-concepts",
    "href": "2025/sessions/day4/session11.html#key-concepts",
    "title": "Session 11",
    "section": "üîë Key Concepts",
    "text": "üîë Key Concepts\n\nPOS tagging\nDependency parsing\nPrecision, Recall, and F1 score",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Session 11"
    ]
  },
  {
    "objectID": "2025/sessions/day4/session11.html#required-readings",
    "href": "2025/sessions/day4/session11.html#required-readings",
    "title": "Session 11",
    "section": "üìö Required Readings",
    "text": "üìö Required Readings\n\nSkim Durrant Ch 6 (Ignore R codes if you are not familiar)",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Session 11"
    ]
  },
  {
    "objectID": "2025/sessions/day4/session11.html#recommended-readings",
    "href": "2025/sessions/day4/session11.html#recommended-readings",
    "title": "Session 11",
    "section": "Recommended Readings",
    "text": "Recommended Readings\n\nKyle, K., & Eguchi, M. (2024). Evaluating NLP models with written and spoken L2 samples. Research Methods in Applied Linguistics, 3(2), 100120. https://doi.org/10.1016/j.rmal.2024.100120",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Session 11"
    ]
  },
  {
    "objectID": "2025/sessions/day4/session11.html#notes",
    "href": "2025/sessions/day4/session11.html#notes",
    "title": "Session 11",
    "section": "üìù Notes",
    "text": "üìù Notes\n\nAll the python codes are prepared by the instructor and shared with the students. This session does not require ability to code.\nThe decision to use Python programming language rather than already available software is based on consideration that there is very little tools which provide stable access to the language analysis described here.",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Session 11"
    ]
  },
  {
    "objectID": "2025/sessions/day4/session11.html#tools-used",
    "href": "2025/sessions/day4/session11.html#tools-used",
    "title": "Session 11",
    "section": "üõ†Ô∏è Tools Used",
    "text": "üõ†Ô∏è Tools Used\n\nTagAnt\nSimple Text Analyzer: A web app created for you.\nGoogle Colaboratory",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Session 11"
    ]
  },
  {
    "objectID": "2025/sessions/day4/session11.html#materials",
    "href": "2025/sessions/day4/session11.html#materials",
    "title": "Session 11",
    "section": "Materials",
    "text": "Materials\n\nSlides (Under construction)",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Session 11"
    ]
  },
  {
    "objectID": "2025/sessions/day4/session11.html#reflection",
    "href": "2025/sessions/day4/session11.html#reflection",
    "title": "Session 11",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Session 11"
    ]
  },
  {
    "objectID": "2025/sessions/day4/index.html",
    "href": "2025/sessions/day4/index.html",
    "title": "Day 4: Analyzing Grammar",
    "section": "",
    "text": "Day 4 introduces grammatical analysis in corpus linguistics, exploring complexity measures and computational tools for parsing and analysis.",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Day 4: Analyzing Grammar"
    ]
  },
  {
    "objectID": "2025/sessions/day4/index.html#overview",
    "href": "2025/sessions/day4/index.html#overview",
    "title": "Day 4: Analyzing Grammar",
    "section": "",
    "text": "Day 4 introduces grammatical analysis in corpus linguistics, exploring complexity measures and computational tools for parsing and analysis.",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Day 4: Analyzing Grammar"
    ]
  },
  {
    "objectID": "2025/sessions/day4/index.html#key-concepts",
    "href": "2025/sessions/day4/index.html#key-concepts",
    "title": "Day 4: Analyzing Grammar",
    "section": "Key Concepts",
    "text": "Key Concepts\n\nGrammatical complexity\nPredictive measures versus Descriptive measures\nPOS tagging\nDependency parsing\nPrecision, Recall, and F1 score\nSyntactic sophistication and fine-grained measures",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Day 4: Analyzing Grammar"
    ]
  },
  {
    "objectID": "2025/sessions/day4/index.html#preparation",
    "href": "2025/sessions/day4/index.html#preparation",
    "title": "Day 4: Analyzing Grammar",
    "section": "Preparation",
    "text": "Preparation\nBefore Day 4:\n\nRead:\n\nDurrant Ch. 5\nKyle, K., & Crossley, S. A. (2018). Measuring Syntactic Complexity in L2 Writing Using Fine‚ÄêGrained Clausal and Phrasal Indices. The Modern Language Journal, 102(2), 333‚Äì349.\n\nSkim:\n\nDurrant Ch. 6 (Ignore R codes if you are not familiar)",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Day 4: Analyzing Grammar"
    ]
  },
  {
    "objectID": "2025/sessions/day4/index.html#schedule",
    "href": "2025/sessions/day4/index.html#schedule",
    "title": "Day 4: Analyzing Grammar",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nTime\nActivity\n\n\n\n\n10:30-12:00\nSession 10: Grammar ‚Äî Overview\n\n\n12:00-13:00\nLunch\n\n\n13:00-14:30\nSession 11: POS Tagging and Parsing\n\n\n14:30-14:40\nBreak\n\n\n14:40-16:10\nSession 12: Linguistic Complexity Analysis",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Day 4: Analyzing Grammar"
    ]
  },
  {
    "objectID": "2025/sessions/day4/index.html#assignments",
    "href": "2025/sessions/day4/index.html#assignments",
    "title": "Day 4: Analyzing Grammar",
    "section": "Assignments",
    "text": "Assignments\n\nDue Tomorrow: Hands-on Assignment 4\nComplete grammatical analysis exercises using Python notebooks and TagAnt",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Day 4: Analyzing Grammar"
    ]
  },
  {
    "objectID": "2025/sessions/day4/index.html#reflection",
    "href": "2025/sessions/day4/index.html#reflection",
    "title": "Day 4: Analyzing Grammar",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 4",
      "Day 4: Analyzing Grammar"
    ]
  },
  {
    "objectID": "2025/sessions/day3/session9.html",
    "href": "2025/sessions/day3/session9.html",
    "title": "Session 9",
    "section": "",
    "text": "By the end of this session, students will be able to:\n\nConduct a simple statistical analysis of selected corpus on small sets of lexical measures using JASP software\nArticulate their mini-project research topic in group\nArticulate their research questions and hypotheses in a 3-minute brief presentation\n\n\n\n\n\n\nLinear regression analysis (group comparison or prediction)\nIntroduction to in-class mini-project\n\n\n\n\n\nNo new reading! (please re-read Eguchi & Kyle, 2020)\n\n\n\n\n\nPaquot, M. (2019). The phraseological dimension in interlanguage complexity research. Second Language Research, 35(1), 121‚Äì145. https://doi.org/10.1177/0267658317694221\nEguchi, M., & Kyle, K. (2023). L2 collocation profiles and their relationship with vocabulary proficiency: A learner corpus approach. Journal of Second Language Writing, 60, 100975. https://doi.org/10.1016/j.jslw.2023.100975",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Session 9"
    ]
  },
  {
    "objectID": "2025/sessions/day3/session9.html#one-liner",
    "href": "2025/sessions/day3/session9.html#one-liner",
    "title": "Session 9",
    "section": "",
    "text": "By the end of this session, students will be able to:\n\nConduct a simple statistical analysis of selected corpus on small sets of lexical measures using JASP software\nArticulate their mini-project research topic in group\nArticulate their research questions and hypotheses in a 3-minute brief presentation\n\n\n\n\n\n\nLinear regression analysis (group comparison or prediction)\nIntroduction to in-class mini-project\n\n\n\n\n\nNo new reading! (please re-read Eguchi & Kyle, 2020)\n\n\n\n\n\nPaquot, M. (2019). The phraseological dimension in interlanguage complexity research. Second Language Research, 35(1), 121‚Äì145. https://doi.org/10.1177/0267658317694221\nEguchi, M., & Kyle, K. (2023). L2 collocation profiles and their relationship with vocabulary proficiency: A learner corpus approach. Journal of Second Language Writing, 60, 100975. https://doi.org/10.1016/j.jslw.2023.100975",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Session 9"
    ]
  },
  {
    "objectID": "2025/sessions/day3/session9.html#materials",
    "href": "2025/sessions/day3/session9.html#materials",
    "title": "Session 9",
    "section": "Materials",
    "text": "Materials\n\nSlides (Under construction)",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Session 9"
    ]
  },
  {
    "objectID": "2025/sessions/day3/session9.html#reflection",
    "href": "2025/sessions/day3/session9.html#reflection",
    "title": "Session 9",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Session 9"
    ]
  },
  {
    "objectID": "2025/sessions/day3/session7.html#learning-objectives",
    "href": "2025/sessions/day3/session7.html#learning-objectives",
    "title": "Session 7",
    "section": "üéØ Learning Objectives",
    "text": "üéØ Learning Objectives\n\nBy the end of this session, students will be able to:\n\nExplain different types of multiword units: collocation, n-grams, lexical bundles\nDemonstrate how major association strengths measures (t-score, Mutual Information, and LogDice) are calculated using examples",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Session 7"
    ]
  },
  {
    "objectID": "2025/sessions/day3/session7.html#key-concepts",
    "href": "2025/sessions/day3/session7.html#key-concepts",
    "title": "Session 7",
    "section": "üîë Key Concepts",
    "text": "üîë Key Concepts\n\nTypes of multiword units\nAssociation strengths\nThree approaches:\n\nContext window\nDependency bigram",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Session 7"
    ]
  },
  {
    "objectID": "2025/sessions/day3/session7.html#required-readings",
    "href": "2025/sessions/day3/session7.html#required-readings",
    "title": "Session 7",
    "section": "üìö Required Readings",
    "text": "üìö Required Readings\n\nDurrant (2023) Ch. 7\nGablasova, D., Brezina, V., & McEnery, T. (2017). Collocations in Corpus‚ÄêBased Language Learning Research: Identifying, Comparing, and Interpreting the Evidence. Language Learning, 67(S1), 155‚Äì179. https://doi.org/10.1111/lang.12225",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Session 7"
    ]
  },
  {
    "objectID": "2025/sessions/day3/session7.html#materials",
    "href": "2025/sessions/day3/session7.html#materials",
    "title": "Session 7",
    "section": "Materials",
    "text": "Materials\n\nSlides (Under construction)",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Session 7"
    ]
  },
  {
    "objectID": "2025/sessions/day3/session7.html#reflection",
    "href": "2025/sessions/day3/session7.html#reflection",
    "title": "Session 7",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 3",
      "Session 7"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session4.html#learning-objectives",
    "href": "2025/sessions/day2/session4.html#learning-objectives",
    "title": "Session 4",
    "section": "üéØ Learning Objectives",
    "text": "üéØ Learning Objectives\n\nBy the end of this session, students will be able to:\n\nExplain the purposes of linguistic measures\nList commonly used lexical measures in second language acquisition research\nExplain sub-constructs of lexical richness measures\n\nLexical Diversity\nLexical Sophistication",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 4"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session4.html#key-concepts",
    "href": "2025/sessions/day2/session4.html#key-concepts",
    "title": "Session 4",
    "section": "üîë Key Concepts",
    "text": "üîë Key Concepts\n\nLexical Richness\n\nDistinction between text internal vs external measures\n\nLexical Diversity\n\nType-Token Ratio\nMeasure of Textual Lexical Diversity (MTLD)\n\nLexical Sophistication\n\nFrequency\nConcreteness\nPhonological neighbors",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 4"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session4.html#required-readings",
    "href": "2025/sessions/day2/session4.html#required-readings",
    "title": "Session 4",
    "section": "üìö Required Readings",
    "text": "üìö Required Readings\n\nDurrant Ch. 3\n(Skim) Eguchi, M., & Kyle, K. (2020). Continuing to Explore the Multidimensional Nature of Lexical Sophistication: The Case of Oral Proficiency Interviews. The Modern Language Journal, 104(2), 381‚Äì400. https://doi.org/10.1111/modl.12637",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 4"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session4.html#materials",
    "href": "2025/sessions/day2/session4.html#materials",
    "title": "Session 4",
    "section": "Materials",
    "text": "Materials\n\nSlides (Under construction)",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 4"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session4.html#reflection",
    "href": "2025/sessions/day2/session4.html#reflection",
    "title": "Session 4",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 4"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session6.html#learning-objectives",
    "href": "2025/sessions/day2/session6.html#learning-objectives",
    "title": "Session 6",
    "section": "üéØ Learning Objectives",
    "text": "üéØ Learning Objectives\nBy the end of this session, you will be able to:\n\n\nCompute simple lexical diversity measures using spreadsheet software\nExplain how modern lexical diversity measures are calculated\nCompute simple lexical sophistication measures\nCalculate simple lexical sophistication measures using dedicated web application\nDescribe how lexical sophistication measures behave on a single input text.\nDiscuss benefits and drawbacks of lexical richness measures.",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 6"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session6.html#key-concepts",
    "href": "2025/sessions/day2/session6.html#key-concepts",
    "title": "Session 6",
    "section": "üîë Key Concepts",
    "text": "üîë Key Concepts\n\nlexical diversity\nlexical sophistication\nLearner corpus research",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 6"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session6.html#tools-used",
    "href": "2025/sessions/day2/session6.html#tools-used",
    "title": "Session 6",
    "section": "üõ†Ô∏è Tools Used",
    "text": "üõ†Ô∏è Tools Used\n\nSimple Text Analyzer: A web app created for you.",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 6"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session6.html#required-readings",
    "href": "2025/sessions/day2/session6.html#required-readings",
    "title": "Session 6",
    "section": "üìö Required Readings",
    "text": "üìö Required Readings\n\n(Skim) Durrant Ch. 4 (Ignore R codes if you are not familiar)",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 6"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session6.html#dive-deeper---recommended-readings",
    "href": "2025/sessions/day2/session6.html#dive-deeper---recommended-readings",
    "title": "Session 6",
    "section": "üåä Dive Deeper - Recommended Readings",
    "text": "üåä Dive Deeper - Recommended Readings\n\nBestgen, Y. (2025). Estimating lexical diversity using the moving average type-token ratio (MATTR): Pros and cons. Research Methods in Applied Linguistics, 4(1), 100168. https://doi.org/10.1016/j.rmal.2024.100168\nKyle, K., Crossley, S., & Berger, C. (2018). The tool for the automatic analysis of lexical sophistication (TAALES): Version 2.0. Behavior Research Methods, 50(3), 1030‚Äì1046. https://doi.org/10.3758/s13428-017-0924-4\nKyle, K., Crossley, S. A., & Jarvis, S. (2021). Assessing the Validity of Lexical Diversity Indices Using Direct Judgements. Language Assessment Quarterly, 18(2), 154‚Äì170. https://doi.org/10.1080/15434303.2020.1844205\nKyle, K., Sung, H., Eguchi, M., & Zenker, F. (2024). Evaluating evidence for the reliability and validity of lexical diversity indices in L2 oral task responses. Studies in Second Language Acquisition, 46(1), 278‚Äì299. https://doi.org/10.1017/S0272263123000402",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 6"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session6.html#materials",
    "href": "2025/sessions/day2/session6.html#materials",
    "title": "Session 6",
    "section": "Materials",
    "text": "Materials\n\nSlides (Under construction)",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 6"
    ]
  },
  {
    "objectID": "2025/sessions/day2/session6.html#reflection",
    "href": "2025/sessions/day2/session6.html#reflection",
    "title": "Session 6",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 2",
      "Session 6"
    ]
  },
  {
    "objectID": "2025/sessions/day5/session15.html#learning-objectives",
    "href": "2025/sessions/day5/session15.html#learning-objectives",
    "title": "Session 15",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this session, you will be able to:",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Session 15"
    ]
  },
  {
    "objectID": "2025/sessions/day5/session15.html#key-concepts",
    "href": "2025/sessions/day5/session15.html#key-concepts",
    "title": "Session 15",
    "section": "Key Concepts",
    "text": "Key Concepts\n\nlinguistic intuition\nscientific hypothesis vs data",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Session 15"
    ]
  },
  {
    "objectID": "2025/sessions/day5/session15.html#materials",
    "href": "2025/sessions/day5/session15.html#materials",
    "title": "Session 15",
    "section": "Materials",
    "text": "Materials\n\nSlides (Under construction)",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Session 15"
    ]
  },
  {
    "objectID": "2025/sessions/day5/session15.html#reflection",
    "href": "2025/sessions/day5/session15.html#reflection",
    "title": "Session 15",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Session 15"
    ]
  },
  {
    "objectID": "2025/sessions/day5/session13.html#learning-objectives",
    "href": "2025/sessions/day5/session13.html#learning-objectives",
    "title": "Session 13",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nBy the end of this session, students will be able to:\n\nDescribe how LLMs are trained generally and what LLMs do to produce language.\nDemonstrate/discuss potential impacts of prompts on the LLMs performance on linguistic annotation.\nExplain the benefits and drawbacks of using LLMs for linguistic annotation.\nDesign an experiment to investigate LLMs output accuracy on a given annotation task.",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Session 13"
    ]
  },
  {
    "objectID": "2025/sessions/day5/session13.html#key-concepts",
    "href": "2025/sessions/day5/session13.html#key-concepts",
    "title": "Session 13",
    "section": "Key Concepts",
    "text": "Key Concepts\n\nLarge Language Models (LLMs) and Language Generation\nPropt engineering\nFine-tuning",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Session 13"
    ]
  },
  {
    "objectID": "2025/sessions/day5/session13.html#required-readings",
    "href": "2025/sessions/day5/session13.html#required-readings",
    "title": "Session 13",
    "section": "üìö Required Readings",
    "text": "üìö Required Readings\n\nMizumoto, A., Shintani, N., Sasaki, M., & Teng, M. F. (2024). Testing the viability of ChatGPT as a companion in L2 writing accuracy assessment. Research Methods in Applied Linguistics, 3(2), 100116. https://doi.org/10.1016/j.rmal.2024.100116\n(Skim) Kim, M., & Lu, X. (2024). Exploring the potential of using ChatGPT for rhetorical move-step analysis: The impact of prompt refinement, few-shot learning, and fine-tuning. Journal of English for Academic Purposes, 71, 101422. https://doi.org/10.1016/j.jeap.2024.101422",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Session 13"
    ]
  },
  {
    "objectID": "2025/sessions/day5/session13.html#recommended-readings",
    "href": "2025/sessions/day5/session13.html#recommended-readings",
    "title": "Session 13",
    "section": "Recommended Readings",
    "text": "Recommended Readings\n\nMizumoto, A. (2025). Automated analysis of common errors in L2 learner production: Prototype web application development. Studies in Second Language Acquisition, 1‚Äì18. https://doi.org/10.1017/S0272263125100934\nYu, D., Li, L., Su, H., & Fuoli, M. (2024). Assessing the potential of LLM-assisted annotation for corpus-based pragmatics and discourse analysis: The case of apology. International Journal of Corpus Linguistics, 29(4), 534‚Äì561. https://doi.org/10.1075/ijcl.23087.yu",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Session 13"
    ]
  },
  {
    "objectID": "2025/sessions/day5/session13.html#materials",
    "href": "2025/sessions/day5/session13.html#materials",
    "title": "Session 13",
    "section": "Materials",
    "text": "Materials\n\nSlides (Under construction)\nPost by Mark Davies on how similar LLM‚Äôs ‚Äúintrospections‚Äù are to corpus data",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Session 13"
    ]
  },
  {
    "objectID": "2025/sessions/day5/session13.html#reflection",
    "href": "2025/sessions/day5/session13.html#reflection",
    "title": "Session 13",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 5",
      "Session 13"
    ]
  },
  {
    "objectID": "2025/sessions/day1/session1.html#learning-objectives",
    "href": "2025/sessions/day1/session1.html#learning-objectives",
    "title": "Session 1",
    "section": "üéØ Learning Objectives",
    "text": "üéØ Learning Objectives\n\nBy the end of this session, students will be able to:\n\nOverview the content of the current course\nExplain key success criteria in this course\nConduct the very first corpus search\nExplain different types of corpus linguistic analysis for different focus: frequency analysis, concordance analysis, collocation analysis, Part-Of-Speech Tagging, etc.",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 1"
    ]
  },
  {
    "objectID": "2025/sessions/day1/session1.html#key-concepts",
    "href": "2025/sessions/day1/session1.html#key-concepts",
    "title": "Session 1",
    "section": "üîë Key Concepts",
    "text": "üîë Key Concepts\n\nConceptual Overview of the corpus linguistic methods\n\nFrequency\nConcordance\nCollocation analysis\nPart-Of-Speech Tagging\nDependency Parsing",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 1"
    ]
  },
  {
    "objectID": "2025/sessions/day1/session1.html#required-readings",
    "href": "2025/sessions/day1/session1.html#required-readings",
    "title": "Session 1",
    "section": "üìö Required Readings",
    "text": "üìö Required Readings\n\n(Skim) Davies (2015) Available through Google Classroom",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 1"
    ]
  },
  {
    "objectID": "2025/sessions/day1/session1.html#notes",
    "href": "2025/sessions/day1/session1.html#notes",
    "title": "Session 1",
    "section": "üìù Notes",
    "text": "üìù Notes\nNeeds analysis (After giving overview) is conducted at the end of this session.",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 1"
    ]
  },
  {
    "objectID": "2025/sessions/day1/session1.html#materials",
    "href": "2025/sessions/day1/session1.html#materials",
    "title": "Session 1",
    "section": "Materials",
    "text": "Materials\n\nView slides in fullscreen",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 1"
    ]
  },
  {
    "objectID": "2025/sessions/day1/session1.html#reflection",
    "href": "2025/sessions/day1/session1.html#reflection",
    "title": "Session 1",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 1"
    ]
  },
  {
    "objectID": "2025/sessions/day1/session3.html",
    "href": "2025/sessions/day1/session3.html",
    "title": "Session 3: Hands-on 1",
    "section": "",
    "text": "You will learn how to conduct basic corpus search.",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 3: Hands-on 1"
    ]
  },
  {
    "objectID": "2025/sessions/day1/session3.html#one-liner",
    "href": "2025/sessions/day1/session3.html#one-liner",
    "title": "Session 3: Hands-on 1",
    "section": "",
    "text": "You will learn how to conduct basic corpus search.",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 3: Hands-on 1"
    ]
  },
  {
    "objectID": "2025/sessions/day1/session3.html#learning-objectives",
    "href": "2025/sessions/day1/session3.html#learning-objectives",
    "title": "Session 3: Hands-on 1",
    "section": "üéØ Learning Objectives",
    "text": "üéØ Learning Objectives\n\nBy the end of this session, students will be able to:\n\nConduct the KWIC search based on chosen corpus\nRun frequency analysis on a Web Corpus",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 3: Hands-on 1"
    ]
  },
  {
    "objectID": "2025/sessions/day1/session3.html#key-concepts",
    "href": "2025/sessions/day1/session3.html#key-concepts",
    "title": "Session 3: Hands-on 1",
    "section": "üîë Key Concepts",
    "text": "üîë Key Concepts\n\nKey Words In Context (KWIC)\nLexical Counting unit:\n\nToken\nLemma\nType\n\nRegular Expressions",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 3: Hands-on 1"
    ]
  },
  {
    "objectID": "2025/sessions/day1/session3.html#tools-used",
    "href": "2025/sessions/day1/session3.html#tools-used",
    "title": "Session 3: Hands-on 1",
    "section": "üõ†Ô∏è Tools Used",
    "text": "üõ†Ô∏è Tools Used\n\nEnglish-Corpora.org\nAntConc",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 3: Hands-on 1"
    ]
  },
  {
    "objectID": "2025/sessions/day1/session3.html#materials",
    "href": "2025/sessions/day1/session3.html#materials",
    "title": "Session 3: Hands-on 1",
    "section": "Materials",
    "text": "Materials\n\nSlides (Opens in new window) \n\n\nEmbedded Slides\n\n\nView slides in fullscreen",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 3: Hands-on 1"
    ]
  },
  {
    "objectID": "2025/sessions/day1/session3.html#reflection",
    "href": "2025/sessions/day1/session3.html#reflection",
    "title": "Session 3: Hands-on 1",
    "section": "Reflection",
    "text": "Reflection",
    "crumbs": [
      "Sessions",
      "Day 1",
      "Session 3: Hands-on 1"
    ]
  },
  {
    "objectID": "2025/notebooks/session-6.html",
    "href": "2025/notebooks/session-6.html",
    "title": "Session 6 ‚Äî Computing simple lexical diversity and sophistication index",
    "section": "",
    "text": "Show code\nlow_diversity = \"The dog ran. The dog jumped. The dog played. The dog barked. The dog ran again and jumped again.\"\nShow code\n\nhigh_diversity = \"A curious fox trotted briskly through the meadow, leaping over mossy logs, sniffing wildflowers, and vanishing into golden twilight.\"\nShow code\ndef count_token_type(text: str):\n    # delete punctuation\n    text = text.replace(\".\", \"\")\n    text = text.replace(\",\", \"\")\n    text = text.replace(\"?\", \"\")\n\n    \n    token_list = text.strip()\n    token_list = text.split(\" \")\n\n    token = len(token_list)\n    type = len(set(token_list))\n    return (token, type)\nShow code\ncount_token_type(low_diversity)\n\n\n(19, 8)\nShow code\ncount_token_type(high_diversity)\n\n\n(19, 19)\nShow code\nlow_diversity2 = \"The dog ran. The dog jumped. The dog barked. The dog played. The dog ran quickly. The dog jumped so high. The dog barked very loudly. The dog played, sat, and rolled. The dog sneezed. The dog ate the food.\"\nShow code\ncount_token_type(low_diversity2)\n\n\n(40, 18)\nShow code\nlow_diversity3 = \"The parrot squawked loudly. The parrot chirped again. A toucan perched nearby. The parrot fluttered. Wings flapped softly. The parrot chirped again. Feathers shimmered under sunlight. The crow cawed. The parrot glided low. The air shimmered. The owl blinked slowly. The parrot perched again. The owl blinked slowly. The parrot shrieked. The parrot chirped nearby again. The parrot squawked again.\"\nShow code\ncount_token_type(low_diversity3)\n\n\n(60, 27)"
  },
  {
    "objectID": "2025/notebooks/session-6.html#using-lexical-diversity-package",
    "href": "2025/notebooks/session-6.html#using-lexical-diversity-package",
    "title": "Session 6 ‚Äî Computing simple lexical diversity and sophistication index",
    "section": "Using Lexical Diversity package",
    "text": "Using Lexical Diversity package\nThere is a package called TAALED maintained by Dr.¬†Kris Kyle.\n\n\nShow code\nfrom taaled import ld\nfrom pylats import lats"
  },
  {
    "objectID": "resources/code-examples/index.html",
    "href": "resources/code-examples/index.html",
    "title": "Code Examples",
    "section": "",
    "text": "Python Notebooks\nSpreadsheet Templates",
    "crumbs": [
      "Resources",
      "Code Examples"
    ]
  },
  {
    "objectID": "resources/code-examples/index.html#available-resources",
    "href": "resources/code-examples/index.html#available-resources",
    "title": "Code Examples",
    "section": "",
    "text": "Python Notebooks\nSpreadsheet Templates",
    "crumbs": [
      "Resources",
      "Code Examples"
    ]
  },
  {
    "objectID": "resources/tools/index.html",
    "href": "resources/tools/index.html",
    "title": "Tools and Software",
    "section": "",
    "text": "AntConc Guide\nBYU Corpora Guide\nPython Setup\nJASP Guide",
    "crumbs": [
      "Resources",
      "Tools",
      "Tools and Software"
    ]
  },
  {
    "objectID": "resources/tools/index.html#available-guides",
    "href": "resources/tools/index.html#available-guides",
    "title": "Tools and Software",
    "section": "",
    "text": "AntConc Guide\nBYU Corpora Guide\nPython Setup\nJASP Guide",
    "crumbs": [
      "Resources",
      "Tools",
      "Tools and Software"
    ]
  },
  {
    "objectID": "resources/index.html",
    "href": "resources/index.html",
    "title": "Resources",
    "section": "",
    "text": "Course resources organized by category.",
    "crumbs": [
      "Resources",
      "Resources"
    ]
  },
  {
    "objectID": "resources/index.html#overview",
    "href": "resources/index.html#overview",
    "title": "Resources",
    "section": "",
    "text": "Course resources organized by category.",
    "crumbs": [
      "Resources",
      "Resources"
    ]
  },
  {
    "objectID": "resources/index.html#categories",
    "href": "resources/index.html#categories",
    "title": "Resources",
    "section": "Categories",
    "text": "Categories\n\nTools and Software\nCorpora\nCode Examples",
    "crumbs": [
      "Resources",
      "Resources"
    ]
  },
  {
    "objectID": "resources/corpora/learner-corpora.html",
    "href": "resources/corpora/learner-corpora.html",
    "title": "Learner Corpora",
    "section": "",
    "text": "Content to be added.",
    "crumbs": [
      "Resources",
      "Corpora",
      "Learner Corpora"
    ]
  },
  {
    "objectID": "resources/corpora/learner-corpora.html#placeholder",
    "href": "resources/corpora/learner-corpora.html#placeholder",
    "title": "Learner Corpora",
    "section": "",
    "text": "Content to be added.",
    "crumbs": [
      "Resources",
      "Corpora",
      "Learner Corpora"
    ]
  },
  {
    "objectID": "2025/slides/session-3.html#objectives",
    "href": "2025/slides/session-3.html#objectives",
    "title": "Session 3: Hands-on #1",
    "section": "Objectives",
    "text": "Objectives\nBy the end of this session, you will be able to:\n\nConduct Basic Corpus search, including KWIC.\nSort KWIC search results to obtain qualitative observation about language use\nUse advanced search strings such as regular expression to fine-tune the search results"
  },
  {
    "objectID": "2025/slides/session-3.html#task-a---simple-word-search",
    "href": "2025/slides/session-3.html#task-a---simple-word-search",
    "title": "Session 3: Hands-on #1",
    "section": "Task A - Simple word search",
    "text": "Task A - Simple word search"
  },
  {
    "objectID": "2025/slides/session-3.html#first-corpus-search",
    "href": "2025/slides/session-3.html#first-corpus-search",
    "title": "Session 3: Hands-on #1",
    "section": "First corpus search",
    "text": "First corpus search\n\nLet‚Äôs start our journey.\nFirst of all, let‚Äôs search the following word in COCA.\n\nrun"
  },
  {
    "objectID": "2025/slides/session-3.html#result-of-dog",
    "href": "2025/slides/session-3.html#result-of-dog",
    "title": "Session 3: Hands-on #1",
    "section": "Result of dog",
    "text": "Result of dog\n\nYou might get slightly different results."
  },
  {
    "objectID": "2025/slides/session-3.html#result-of-run",
    "href": "2025/slides/session-3.html#result-of-run",
    "title": "Session 3: Hands-on #1",
    "section": "Result of run",
    "text": "Result of run\n\nSearch - run\nYou might get slightly different results."
  },
  {
    "objectID": "2025/slides/session-3.html#lemma-search",
    "href": "2025/slides/session-3.html#lemma-search",
    "title": "Session 3: Hands-on #1",
    "section": "LEMMA search",
    "text": "LEMMA search\n\nLemma is a group of word form for the head-word with grammatical inflection.\nYou can search LEMMA in English-Corpora.org through Capital letters.\nThe search methods will depend on the corpus tool you use."
  },
  {
    "objectID": "2025/slides/session-3.html#lemma-search-1",
    "href": "2025/slides/session-3.html#lemma-search-1",
    "title": "Session 3: Hands-on #1",
    "section": "LEMMA search",
    "text": "LEMMA search\n\nSearch - consider"
  },
  {
    "objectID": "2025/slides/session-3.html#concordances-or-kwic",
    "href": "2025/slides/session-3.html#concordances-or-kwic",
    "title": "Session 3: Hands-on #1",
    "section": "Concordances (or KWIC)",
    "text": "Concordances (or KWIC)\n\nNow you know how many times XX occurs in COCA, you want to see the context in which XX occur.\nThis goal can be accomplished with KWIC search."
  },
  {
    "objectID": "2025/slides/session-3.html#kwic-view",
    "href": "2025/slides/session-3.html#kwic-view",
    "title": "Session 3: Hands-on #1",
    "section": "KWIC view",
    "text": "KWIC view\n\nGo back to SEARCH window.\n\n\nKWIC search"
  },
  {
    "objectID": "2025/slides/session-3.html#kwic-view-1",
    "href": "2025/slides/session-3.html#kwic-view-1",
    "title": "Session 3: Hands-on #1",
    "section": "KWIC view",
    "text": "KWIC view\n\nClick on the + button in the search menu and enter your search word.\n\n\nKWIC search"
  },
  {
    "objectID": "2025/slides/session-3.html#kwic-view-2",
    "href": "2025/slides/session-3.html#kwic-view-2",
    "title": "Session 3: Hands-on #1",
    "section": "KWIC view",
    "text": "KWIC view\n\nThe result is displayed. Default sort : R1 &gt; R2 &gt; R3\n\n\nKWIC search"
  },
  {
    "objectID": "2025/slides/session-3.html#sorting-kwic-window",
    "href": "2025/slides/session-3.html#sorting-kwic-window",
    "title": "Session 3: Hands-on #1",
    "section": "Sorting KWIC window",
    "text": "Sorting KWIC window\n\nNow let‚Äôs sort the results according to the position in context.\n\n\nKWIC search"
  },
  {
    "objectID": "2025/slides/session-3.html#sorting-words",
    "href": "2025/slides/session-3.html#sorting-words",
    "title": "Session 3: Hands-on #1",
    "section": "Sorting words",
    "text": "Sorting words\nYou can sort the words.\n\nKWIC search"
  },
  {
    "objectID": "2025/slides/session-3.html#lets-try-kwic",
    "href": "2025/slides/session-3.html#lets-try-kwic",
    "title": "Session 3: Hands-on #1",
    "section": "Let‚Äôs Try: KWIC",
    "text": "Let‚Äôs Try: KWIC\n\nChoose a word that you want to see the context for.\nSearch the word with KWIC.\nSort the word in the following way.\n\nDefault: R1 &gt; R2 &gt; R3\nCustom 1: L1 &gt; L2 &gt; L3\nCustom 2: L1 &gt; R1 &gt; R2"
  },
  {
    "objectID": "2025/slides/session-3.html#how-to-get-custom-1-and-2",
    "href": "2025/slides/session-3.html#how-to-get-custom-1-and-2",
    "title": "Session 3: Hands-on #1",
    "section": "How to get Custom 1 and 2",
    "text": "How to get Custom 1 and 2\n\nKWIC search"
  },
  {
    "objectID": "2025/slides/session-3.html#chart-function",
    "href": "2025/slides/session-3.html#chart-function",
    "title": "Session 3: Hands-on #1",
    "section": "Chart function",
    "text": "Chart function\n\nNow that we learned how to conduct concordance search, let‚Äôs experiment with some CHART function.\nThis allows you to return frequency by sections of of COCA (= conditional frequency)."
  },
  {
    "objectID": "2025/slides/session-3.html#search-radio-using-chart",
    "href": "2025/slides/session-3.html#search-radio-using-chart",
    "title": "Session 3: Hands-on #1",
    "section": "Search radio using CHART",
    "text": "Search radio using CHART\n\nGo to Search Tab, select, CHART and enter radio\n\n\nChart search"
  },
  {
    "objectID": "2025/slides/session-3.html#search-radio-using-chart-1",
    "href": "2025/slides/session-3.html#search-radio-using-chart-1",
    "title": "Session 3: Hands-on #1",
    "section": "Search radio using CHART",
    "text": "Search radio using CHART\n\nYou will get the following:"
  },
  {
    "objectID": "2025/slides/session-3.html#regular-expressions",
    "href": "2025/slides/session-3.html#regular-expressions",
    "title": "Session 3: Hands-on #1",
    "section": "Regular expressions",
    "text": "Regular expressions\nRegular expression (Ê≠£Ë¶èË°®Áèæ) allows you to search corpus through ‚Äúpattern matching‚Äù.\n\nHave you ever used (*) asterisk in your web search?\nThis is one of the regular expression (= wild card)"
  },
  {
    "objectID": "2025/slides/session-3.html#using-wild-card-in-search",
    "href": "2025/slides/session-3.html#using-wild-card-in-search",
    "title": "Session 3: Hands-on #1",
    "section": "Using wild card in search",
    "text": "Using wild card in search\n\nLet‚Äôs go back to List search.\nEnter ‚Äúa * of the‚Äù\nWhat result do you expect with this search?\nDon‚Äôt turn to the next page YET!!!"
  },
  {
    "objectID": "2025/slides/session-3.html#result-with-a-of-the",
    "href": "2025/slides/session-3.html#result-with-a-of-the",
    "title": "Session 3: Hands-on #1",
    "section": "Result with a * of the",
    "text": "Result with a * of the"
  },
  {
    "objectID": "2025/slides/session-3.html#more-search-methods",
    "href": "2025/slides/session-3.html#more-search-methods",
    "title": "Session 3: Hands-on #1",
    "section": "More search methods",
    "text": "More search methods\n\nYou can check how to use other search methods in English-Corpora.org here"
  },
  {
    "objectID": "2025/slides/session-3.html#collocation-search",
    "href": "2025/slides/session-3.html#collocation-search",
    "title": "Session 3: Hands-on #1",
    "section": "Collocation search",
    "text": "Collocation search\n\nThis is main topic for Day 3.\nBriefly, collocates search allows us to search for co-occurring words within specified window."
  },
  {
    "objectID": "2025/slides/session-3.html#collocation-search-1",
    "href": "2025/slides/session-3.html#collocation-search-1",
    "title": "Session 3: Hands-on #1",
    "section": "Collocation search",
    "text": "Collocation search\n\nSelect Collocates"
  },
  {
    "objectID": "2025/slides/session-3.html#collocation-search-2",
    "href": "2025/slides/session-3.html#collocation-search-2",
    "title": "Session 3: Hands-on #1",
    "section": "Collocation search",
    "text": "Collocation search\n\nEnter search word"
  },
  {
    "objectID": "2025/slides/session-3.html#collocation-search-3",
    "href": "2025/slides/session-3.html#collocation-search-3",
    "title": "Session 3: Hands-on #1",
    "section": "Collocation search",
    "text": "Collocation search\n\nOptional enter the word to look for"
  },
  {
    "objectID": "2025/slides/session-3.html#collocation-search-4",
    "href": "2025/slides/session-3.html#collocation-search-4",
    "title": "Session 3: Hands-on #1",
    "section": "Collocation search",
    "text": "Collocation search\n\nSpecify window\n\n\nHow distant do you search for the collocates"
  },
  {
    "objectID": "2025/slides/session-5.html#housekeeping",
    "href": "2025/slides/session-5.html#housekeeping",
    "title": "Session 5: Hands-on activity #2",
    "section": "Housekeeping",
    "text": "Housekeeping\nThis is house keeping"
  },
  {
    "objectID": "2025/slides/session-5.html#session-overview",
    "href": "2025/slides/session-5.html#session-overview",
    "title": "Session 5: Hands-on activity #2",
    "section": "Session overview",
    "text": "Session overview"
  },
  {
    "objectID": "2025/slides/session-5.html#introduction",
    "href": "2025/slides/session-5.html#introduction",
    "title": "Session 5: Hands-on activity #2",
    "section": "Introduction",
    "text": "Introduction\n\nAntConc is free concordancing tool.\nDeveloped by Laurence ANTHONY."
  },
  {
    "objectID": "2025/slides/session-5.html#hands-on-activity",
    "href": "2025/slides/session-5.html#hands-on-activity",
    "title": "Session 5: Hands-on activity #2",
    "section": "Hands-on Activity",
    "text": "Hands-on Activity"
  },
  {
    "objectID": "2025/slides/session-3.html#task-a.2---lemma-search",
    "href": "2025/slides/session-3.html#task-a.2---lemma-search",
    "title": "Session 3: Hands-on #1",
    "section": "Task A.2 - LEMMA search",
    "text": "Task A.2 - LEMMA search"
  },
  {
    "objectID": "2025/slides/session-5.html#word",
    "href": "2025/slides/session-5.html#word",
    "title": "Session 5: Hands-on activity #2",
    "section": "Word",
    "text": "Word\nLet‚Äôs now create a frequency list\n\nSelect Word analysis option\nSet Min. Freq and Min. Range\n\n\nMin. Freq = the number of times the word should occur in the corpus\nMin. Range = the number of files in which the word should occur\n\n\nHit Start"
  },
  {
    "objectID": "2025/slides/session-5.html#lets-try",
    "href": "2025/slides/session-5.html#lets-try",
    "title": "Session 5: Hands-on activity #2",
    "section": "Let‚Äôs try",
    "text": "Let‚Äôs try\n\nSet min. frequency = 3; min. range = 3"
  },
  {
    "objectID": "2025/slides/session-5.html#saving-the-frequency-list",
    "href": "2025/slides/session-5.html#saving-the-frequency-list",
    "title": "Session 5: Hands-on activity #2",
    "section": "Saving the frequency list",
    "text": "Saving the frequency list\n\nFrom File hit save the current results\n\n\nsave-list"
  },
  {
    "objectID": "2025/slides/session-5.html#result-of-frequency",
    "href": "2025/slides/session-5.html#result-of-frequency",
    "title": "Session 5: Hands-on activity #2",
    "section": "Result of frequency",
    "text": "Result of frequency\n\nWe will use the BROWN frequency list in the next session.\n\n\nsave-list"
  },
  {
    "objectID": "2025/slides/session-5.html#we-will-use-the-brown-frequency-list-in-the-next-session.",
    "href": "2025/slides/session-5.html#we-will-use-the-brown-frequency-list-in-the-next-session.",
    "title": "Session 5: Hands-on activity #2",
    "section": "We will use the BROWN frequency list in the next session.",
    "text": "We will use the BROWN frequency list in the next session."
  },
  {
    "objectID": "2025/slides/session-5.html#frequency-list",
    "href": "2025/slides/session-5.html#frequency-list",
    "title": "Session 5: Hands-on activity #2",
    "section": "Frequency list",
    "text": "Frequency list\n\nWe will use the BROWN frequency list in the next session.\n\n\nsave-list"
  },
  {
    "objectID": "2025/slides/session-5.html#task-1-creating-a-frequency-list",
    "href": "2025/slides/session-5.html#task-1-creating-a-frequency-list",
    "title": "Session 5: Hands-on activity #2",
    "section": "Task 1: Creating a frequency list",
    "text": "Task 1: Creating a frequency list"
  },
  {
    "objectID": "2025/slides/session-5.html#task-2-plot-frequency",
    "href": "2025/slides/session-5.html#task-2-plot-frequency",
    "title": "Session 5: Hands-on activity #2",
    "section": "Task 2: Plot frequency",
    "text": "Task 2: Plot frequency"
  },
  {
    "objectID": "2025/slides/session-5.html#task-2-plot-frequencies",
    "href": "2025/slides/session-5.html#task-2-plot-frequencies",
    "title": "Session 5: Hands-on activity #2",
    "section": "Task 2: Plot frequencies",
    "text": "Task 2: Plot frequencies\n\nLet‚Äôs now understand the distributions of words in language.\nVisit our simple-text-analyzer tool.\nHit Frequency analysis and upload the frequency list.\nWhat did you notice?"
  },
  {
    "objectID": "2025/slides/session-5.html#frequency-plot",
    "href": "2025/slides/session-5.html#frequency-plot",
    "title": "Session 5: Hands-on activity #2",
    "section": "Frequency Plot",
    "text": "Frequency Plot\n\nVery few words occupy most of the corpus.\n\n\nBROWN frequency"
  },
  {
    "objectID": "2025/slides/session-5.html#implication-of-frequency-on-learning-teaching-and-assessment",
    "href": "2025/slides/session-5.html#implication-of-frequency-on-learning-teaching-and-assessment",
    "title": "Session 5: Hands-on activity #2",
    "section": "Implication of frequency on learning, teaching, and assessment",
    "text": "Implication of frequency on learning, teaching, and assessment"
  },
  {
    "objectID": "2025/slides/session-5.html#task-3-lexical-profiling",
    "href": "2025/slides/session-5.html#task-3-lexical-profiling",
    "title": "Session 5: Hands-on activity #2",
    "section": "Task 3: Lexical profiling",
    "text": "Task 3: Lexical profiling\nNow that we understand an important property of language (Zipf‚Äôs law), let‚Äôs conduct lexical profiling."
  },
  {
    "objectID": "2025/slides/session-5.html#optional-task-4-vocabulary-profiling-through-antwordprofiler",
    "href": "2025/slides/session-5.html#optional-task-4-vocabulary-profiling-through-antwordprofiler",
    "title": "Session 5: Hands-on activity #2",
    "section": "(Optional) Task 4: Vocabulary Profiling through AntWordProfiler",
    "text": "(Optional) Task 4: Vocabulary Profiling through AntWordProfiler"
  },
  {
    "objectID": "2025/slides/session-5.html#task-5",
    "href": "2025/slides/session-5.html#task-5",
    "title": "Session 5: Hands-on activity #2",
    "section": "Task 5:",
    "text": "Task 5:"
  },
  {
    "objectID": "2025/slides/session-5.html#task-5-tokenizing-non-english-language-for-frequency-analysis",
    "href": "2025/slides/session-5.html#task-5-tokenizing-non-english-language-for-frequency-analysis",
    "title": "Session 5: Hands-on activity #2",
    "section": "Task 5: Tokenizing non-English language for frequency analysis",
    "text": "Task 5: Tokenizing non-English language for frequency analysis\n\nUp to this point,"
  },
  {
    "objectID": "2025/slides/session-5.html#task-5-tokenizing-non-english-languages-for-frequency-analysis",
    "href": "2025/slides/session-5.html#task-5-tokenizing-non-english-languages-for-frequency-analysis",
    "title": "Session 5: Hands-on activity #2",
    "section": "Task 5: Tokenizing non-English languages for frequency analysis",
    "text": "Task 5: Tokenizing non-English languages for frequency analysis\n\nUp to this point, we only dealt with English.\nEnglish is very convenient in corpus analysis because of the white spaces.\nAsian languages have completely different writing system from Indo-European language, and it makes it difficult to tokenize texts in to words.\nI am planning to eat Oysters after this intensive course.\n„Åì„ÅÆÁü≠ÊúüÈõÜ‰∏≠Ë¨õÂ∫ß„ÅåÁµÇ„Çè„Å£„Åü„Çâ„ÄÅ„Ç´„Ç≠„ÇíÈ£ü„Åπ„Åü„ÅÑ„Å®ÊÄù„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ"
  },
  {
    "objectID": "2025/slides/session-5.html#tagant",
    "href": "2025/slides/session-5.html#tagant",
    "title": "Session 5: Hands-on activity #2",
    "section": "TagAnt",
    "text": "TagAnt\n\nTokenization (segmenting running text into words) needs more advanced statistical algorithms.\nTagAnt is a free tool (again developped by Laurence ANTHONY).\nIt uses modern natural language processing tool (called spaCy) to tokenize input texts."
  },
  {
    "objectID": "2025/slides/session-5.html#lets-try-1",
    "href": "2025/slides/session-5.html#lets-try-1",
    "title": "Session 5: Hands-on activity #2",
    "section": "Let‚Äôs try",
    "text": "Let‚Äôs try\n\nDownload and open TagAnt.\nCopy and paste a sample text into Input Text.\nSelect language.\nSelect Output format."
  },
  {
    "objectID": "2025/slides/session-5.html#result-of",
    "href": "2025/slides/session-5.html#result-of",
    "title": "Session 5: Hands-on activity #2",
    "section": "Result of",
    "text": "Result of"
  },
  {
    "objectID": "2025/slides/session-5.html#result-of-tagant-segmentation",
    "href": "2025/slides/session-5.html#result-of-tagant-segmentation",
    "title": "Session 5: Hands-on activity #2",
    "section": "Result of TagAnt segmentation",
    "text": "Result of TagAnt segmentation\n\n\n\n\n\nHorizontal display\n\n\n\n\n\n\nVertical display"
  },
  {
    "objectID": "2025/slides/session-5.html#tokenizing-japanese",
    "href": "2025/slides/session-5.html#tokenizing-japanese",
    "title": "Session 5: Hands-on activity #2",
    "section": "Tokenizing Japanese",
    "text": "Tokenizing Japanese\n\nDownload and open TagAnt.\nCopy and paste a sample text into Input Text.\nSelect language.\nSelect Output format."
  },
  {
    "objectID": "2025/slides/session-5.html#compile-a-japanese-frequency-list-based-on-corpus.",
    "href": "2025/slides/session-5.html#compile-a-japanese-frequency-list-based-on-corpus.",
    "title": "Session 5: Hands-on activity #2",
    "section": "Compile a Japanese frequency list based on corpus.",
    "text": "Compile a Japanese frequency list based on corpus."
  },
  {
    "objectID": "2025/slides/session-5.html#task",
    "href": "2025/slides/session-5.html#task",
    "title": "Session 5: Hands-on activity #2",
    "section": "Task",
    "text": "Task\nCompile a Japanese frequency list based on corpus.\nResource\n\nDownload a Japanese texts from Google Drive."
  },
  {
    "objectID": "2025/slides/session-5.html#activity-instruction",
    "href": "2025/slides/session-5.html#activity-instruction",
    "title": "Session 5: Hands-on activity #2",
    "section": "Activity instruction",
    "text": "Activity instruction\nTask\nCompile a Japanese frequency list based on corpus.\nResource\n\nDownload a Japanese texts from Google Drive.\nUse AntConc and TagAnt.\n\nSubmission\n\nSubmit a frequency list\nDescription"
  }
]